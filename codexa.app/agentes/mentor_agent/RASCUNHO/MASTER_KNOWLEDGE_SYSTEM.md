# üå≥ MASTER KNOWLEDGE SYSTEM
## LCM-AI + Agentes + Documenta√ß√£o + Claude Code Framework
### Sistema Completo de Gest√£o de Conhecimento para IA

**Vers√£o:** 2.0  
**Autores:** Sistema LCM-AI Core  
**Prop√≥sito:** Documento definitivo integrando arquitetura de conhecimento, workflows de agentes, metodologias de documenta√ß√£o e hierarquia de ferramentas Claude Code

---

## üìö √çNDICE NAVEG√ÅVEL

### PARTE I: FUNDAMENTOS
1. [Vis√£o Geral do Ecossistema](#1-vis√£o-geral)
2. [Princ√≠pios Fundamentais](#2-princ√≠pios-fundamentais)
3. [Met√°fora da √Årvore](#3-met√°fora-da-√°rvore)

### PARTE II: ARQUITETURA LCM-AI
4. [Estrutura de Camadas](#4-estrutura-de-camadas)
5. [Ra√≠zes (‚àí) - Ingest√£o e Arquivo](#5-raizes)
6. [Tronco (‚àû) - Orquestra√ß√£o](#6-tronco)
7. [Galhos (+) - Distribui√ß√£o](#7-galhos)
8. [Folhas (Skills) - Transforma√ß√£o](#8-folhas)
9. [Fruto (13) - Aplica√ß√µes](#9-fruto)

### PARTE III: WORKFLOWS DE AGENTES
10. [Framework Gen√©rico de Agentes](#10-framework-agentes)
11. [Agente 1: Research & Intelligence](#11-agente-research)
12. [Agente 2: Copy Generation](#12-agente-copy)
13. [Agente 3: Visual Generation](#13-agente-visual)
14. [Integra√ß√£o e Orquestra√ß√£o](#14-integracao)

### PARTE IV: HIERARQUIA CLAUDE CODE
15. [Core-4: Contexto, Modelos, Prompt, Ferramentas](#15-core-4)
16. [Slash Commands (Primitivos)](#16-slash-commands)
17. [Subagents (Especializa√ß√£o)](#17-subagents)
18. [MCP (Integra√ß√µes)](#18-mcp)
19. [Skills (Orquestra√ß√£o)](#19-skills)
20. [Plugins (Empacotamento)](#20-plugins)

### PARTE V: META-CONHECIMENTO
21. [Como LLMs Aprendem](#21-como-llms-aprendem)
22. [Destila√ß√£o de Conhecimento](#22-destilacao)
23. [SFT e DPO para Documenta√ß√£o](#23-sft-dpo)
24. [Formatos √ìtimos de Documenta√ß√£o](#24-formatos-otimos)

### PARTE VI: IMPLEMENTA√á√ÉO
25. [Plano de 6 Dias](#25-plano-6-dias)
26. [Configura√ß√µes e Templates](#26-configuracoes)
27. [Testes e Valida√ß√£o](#27-testes)
28. [Antipadr√µes e Boas Pr√°ticas](#28-antipadroes)

### PARTE VII: CASOS DE USO
29. [E-commerce e Marketplace](#29-ecommerce)
30. [Documenta√ß√£o T√©cnica](#30-doc-tecnica)
31. [Gest√£o de Conhecimento](#31-gestao-conhecimento)

### AP√äNDICES
A. [Gloss√°rio Completo](#apendice-a)  
B. [Refer√™ncias e Bibliografia](#apendice-b)  
C. [Cheat Sheets](#apendice-c)

---

## PARTE I: FUNDAMENTOS

### 1. VIS√ÉO GERAL DO ECOSSISTEMA

**O Sistema Integrado:**

```
                    APLICA√á√ïES (13)
                         ‚Üë
                    OUTPUTS (+)
                         ‚Üë
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ         CORE SYSTEM (‚àû)         ‚îÇ
        ‚îÇ    Orquestra√ß√£o ¬∑ Skills        ‚îÇ
        ‚îÇ    Agentes ¬∑ Documenta√ß√£o       ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì
                    INPUTS (‚àí)
                         ‚Üì
                   DADOS BRUTOS
```

Este documento integra **4 sistemas complementares**:

1. **LCM-AI**: Arquitetura de gest√£o de conhecimento (√°rvore viva)
2. **Workflow de Agentes**: Sistema de 3 agentes especializados
3. **Meta-Guia**: Metodologia de documenta√ß√£o para LLMs
4. **Claude Code Framework**: Hierarquia Slash‚ÜíSubagent‚ÜíMCP‚ÜíSkill‚ÜíPlugin

**Princ√≠pio Unificador:**
> "Conhecimento √© vivo quando organizado em camadas, acess√≠vel em contextos, e transform√°vel por agentes especializados"

---

### 2. PRINC√çPIOS FUNDAMENTAIS

#### 2.1 Princ√≠pio do Prompt
> **"The prompt is the new fundamental unit of knowledge work"**

- Todo trabalho come√ßa com um prompt bem estruturado
- Prompts s√£o at√¥micos, compos√≠veis, version√°veis
- Sistema constru√≠do em camadas de abstra√ß√£o sobre prompts

#### 2.2 Princ√≠pio da Separa√ß√£o
> **"Cada camada tem uma responsabilidade √∫nica"**

```
DADOS    ‚â†  PROCESSAMENTO  ‚â†  APRESENTA√á√ÉO
(Ra√≠zes)    (Tronco/Folhas)    (Galhos/Fruto)
```

#### 2.3 Princ√≠pio da Progressividade
> **"Conhecimento √© revelado em camadas progressivas"**

- Usu√°rio novato: TL;DR + Quick Start
- Usu√°rio intermedi√°rio: Guias e exemplos
- Usu√°rio expert: API Reference completa

#### 2.4 Princ√≠pio da Auditabilidade
> **"Tudo √© rastre√°vel, versionado, imut√°vel na origem"**

- SHA256 para integridade
- Append-only logs
- Metadata completo em cada artefato

#### 2.5 Princ√≠pio da Composi√ß√£o
> **"Complexidade emerge de componentes simples"**

- Skills simples ‚Üí Agentes compostos
- Slash commands ‚Üí Skills ‚Üí Subagents
- Nunca duplicar l√≥gica at√¥mica

---

### 3. MET√ÅFORA DA √ÅRVORE

#### 3.1 Por Que √Årvore?

**√Årvore √©:**
- **Viva**: Respira, cresce, se adapta
- **Estruturada**: Ra√≠zes, tronco, galhos, folhas, fruto
- **Fractal**: Cada galho √© uma mini-√°rvore
- **Resiliente**: Se um galho quebra, outros continuam
- **C√≠clica**: Fruto gera semente que vira nova √°rvore

#### 3.2 Anatomia Funcional

```
        üå§Ô∏è SOL (Input/Energia)
        ‚îÇ
      üçé FRUTO (13) ‚Üê Aplica√ß√µes finais
        ‚îÇ
    üçÉ FOLHAS (8/‚àû) ‚Üê Skills (fotoss√≠ntese)
      ‚Üô ‚Üì ‚Üñ
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ  GALHOS (+)     ‚îÇ ‚Üê Distribui√ß√£o
  ‚îÇ  Fluxo PARA     ‚îÇ
  ‚îÇ  FORA           ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
      ‚ïî‚ïê‚ïê‚ïê‚ïê‚àû‚ïê‚ïê‚ïê‚ïê‚ïó
      ‚ïë  TRONCO ‚ïë ‚Üê Orquestra√ß√£o (00_hub)
      ‚ïë CORA√á√ÉO ‚ïë
      ‚ïë  (Core) ‚ïë
      ‚ïö‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïù
           ‚îÇ
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ  RA√çZES (‚àí)     ‚îÇ ‚Üê Ingest√£o & Arquivo
  ‚îÇ  Fluxo PARA     ‚îÇ
  ‚îÇ  DENTRO         ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
        üåç SOLO (Dados brutos: 32k arquivos)
```

#### 3.3 Mapeamento Matem√°tico

**Sua Nota√ß√£o Original:**
- **0 a 8**: A √°rvore em si (input ‚Üí processamento ‚Üí output)
- **8 (‚àû)**: Infinito - A transforma√ß√£o cont√≠nua (Skills)
- **13 (Builder)**: Fora da √°rvore - O fruto (Aplica√ß√µes)

**Tradu√ß√£o para Estrutura:**
```
‚àí08 ‚Üê ‚àí05 ‚Üê ‚àí03 ‚Üê ‚àí02 ‚Üê ‚àí01  (Ra√≠zes: entrada)
                    ‚Üì
                 00_‚àû_hub      (Tronco: cora√ß√£o)
                    ‚Üì
+01 ‚Üí +02 ‚Üí +03 ‚Üí +05 ‚Üí +08   (Galhos: sa√≠da)
                    ‚Üì
              Skills (8=‚àû)     (Folhas: transforma√ß√£o)
                    ‚Üì
                  App (13)     (Fruto: consumo)
```

---

## PARTE II: ARQUITETURA LCM-AI

### 4. ESTRUTURA DE CAMADAS

#### 4.1 Vis√£o Hier√°rquica

```yaml
lcm-ai/
  # TRONCO (Orquestra√ß√£o)
  00_‚àû_hub/
    core.py              # Orquestrador principal
    config.yaml          # Pesos e configura√ß√µes
    system_prompt.md     # Prompt raiz do sistema
    monitoring.jsonl     # Logs de decis√µes
  
  # RA√çZES (Input/Arquivo)
  ‚àí01_capture/           # Solo bruto (dados originais)
  ‚àí02_build/             # F√°brica (artefatos sintetizados)
    ‚àí02A_catalog/        # Cat√°logo naveg√°vel
    ‚àí02B_units/          # Unidades at√¥micas
  ‚àí03_index/             # √çndice e busca
  ‚àí05_storage/           # Armazenamento frio
  ‚àí08_backup/            # Redund√¢ncia
  
  # GALHOS (Output/Distribui√ß√£o)
  +01_intake/            # Porta de entrada
  +02_route/             # Roteamento inteligente
  +03_execute/           # Execu√ß√£o de workflows
  +05_delivery/          # Entrega final
  +08_feedback/          # Feedback loop
  
  # FOLHAS (Transforma√ß√£o)
  skills/
    skill_synthesizer.py
    skill_tokenizer.py
    skill_purpose_extractor.py
    skill_qa_generator.py
    skill_evaluator.py
  
  # VIEWS (Organiza√ß√£o Sem√¢ntica)
  views/
    by-domain/           # Symlinks por dom√≠nio
    by-purpose/          # Symlinks por prop√≥sito
    by-entity/           # Symlinks por entidade
    by-date/             # Symlinks temporais
```

#### 4.2 Fluxo de Dados Completo

```
ENTRADA (Usu√°rio sobe documento)
    ‚Üì
+01_intake/ (Recebe e valida)
    ‚Üì
+02_route/ (Decide: qual workflow?)
    ‚Üì
00_‚àû_hub (Orquestra)
    ‚îú‚Üí skill_synthesizer()    # Resumos
    ‚îú‚Üí skill_tokenizer()       # Chunks
    ‚îú‚Üí skill_purpose_extractor() # Tags
    ‚îú‚Üí skill_qa_generator()    # Q&As
    ‚îî‚Üí skill_evaluator()       # Score
    ‚Üì
TRINITY NASCEU (.md + .llm.json + .meta.json)
    ‚Üì
‚àí02_build/ (Artefatos criados)
‚àí03_index/ (Catalogado)
views/ (Symlinks organizados)
    ‚Üì
+05_delivery/ (Dispon√≠vel)
    ‚Üì
SA√çDA (Usu√°rio/App consome)
    ‚Üì
+08_feedback/ (Aprende com uso)
    ‚Üì
00_‚àû_hub (Atualiza pesos)
    ‚Üì
SISTEMA MAIS INTELIGENTE üß†
```

---

### 5. RA√çZES (‚àí) - INGEST√ÉO E ARQUIVO

#### 5.1 Filosofia

> "Ra√≠zes crescem no escuro, absorvem nutrientes, nunca esquecem"

**Garantias:**
- ‚úÖ Imut√°vel (append-only)
- ‚úÖ Versionado (git + SHA256)
- ‚úÖ Audit√°vel (quem, quando, por qu√™)
- ‚úÖ Redundante (backup autom√°tico)

#### 5.2 Camadas de Ra√≠zes

##### ‚àí01_capture/ (Solo Bruto)
```
Fun√ß√£o: Receber dados originais sem modifica√ß√£o
Estrutura:
  YYYYMMDD/
    HHmmss_<hash>.original
Pol√≠tica: Nunca deletar, nunca modificar
```

##### ‚àí02_build/ (F√°brica)
```
Fun√ß√£o: Sintetizar artefatos
Estrutura:
  domain/entity/purpose/
    artifact.md          # Humano
    artifact.llm.json    # IA
    artifact.meta.json   # Metadados
Pol√≠tica: Imut√°vel ap√≥s cria√ß√£o
```

##### ‚àí03_index/ (Cat√°logo)
```
Fun√ß√£o: Busca e navega√ß√£o
Estrutura:
  search.db            # SQLite full-text
  embeddings.faiss     # Vetores para busca sem√¢ntica
  taxonomy.yaml        # √Årvore de conceitos
Pol√≠tica: Rebuild peri√≥dico
```

##### ‚àí05_storage/ (Frio)
```
Fun√ß√£o: Dados antigos mas preservados
Estrutura:
  YYYY/MM/
    archived_*.tar.gz
Pol√≠tica: Compress + encrypt
```

##### ‚àí08_backup/ (Redund√¢ncia)
```
Fun√ß√£o: Disaster recovery
Estrutura:
  daily/
  weekly/
  monthly/
Pol√≠tica: 3-2-1 (3 c√≥pias, 2 m√≠dias, 1 offsite)
```

#### 5.3 Trinity Format

**Cada artefato gera 3 arquivos:**

**1. artifact.md (Humano)**
```markdown
# T√≠tulo do Artefato

## Resumo (1 linha)
Ess√™ncia em uma senten√ßa.

## Resumo (2 linhas)
Contexto + valor principal.

## Resumo (3 linhas)
Problema + solu√ß√£o + benef√≠cio.

## Resumo (5 linhas)
[Fibonacci: mais detalhes]

## Resumo (8 linhas)
[Fibonacci: contexto completo]

## Conte√∫do Principal
[Texto completo processado]

## Metadados
- Domain: [domain]
- Entity: [entity]
- Purpose: [purpose]
- Keywords: [tag1, tag2, tag3]

## Q&A
1. **Q:** [pergunta autom√°tica]  
   **A:** [resposta inferida]

[... 5 pares Q&A ...]
```

**2. artifact.llm.json (IA)**
```json
{
  "id": "sha256_hash",
  "content": {
    "full": "texto completo",
    "summaries": {
      "1": "uma linha",
      "2": "duas linhas",
      "3": "tr√™s linhas",
      "5": "cinco linhas",
      "8": "oito linhas"
    },
    "chunks": {
      "128": ["chunk1_128tokens", "chunk2_128tokens"],
      "256": ["chunk1_256tokens"],
      "384": ["chunk1_384tokens"],
      "640": ["chunk1_640tokens"],
      "1024": ["chunk1_1024tokens"]
    }
  },
  "metadata": {
    "domain": "domain_name",
    "entity": "entity_name",
    "purpose": ["purpose1", "purpose2"],
    "keywords": ["kw1", "kw2", "kw3"],
    "quality_score": 0.92,
    "created_at": "2025-01-15T10:30:00Z"
  },
  "qa_pairs": [
    {"question": "...", "answer": "..."},
    {"question": "...", "answer": "..."}
  ],
  "embeddings": {
    "model": "text-embedding-3-large",
    "vector": [0.123, -0.456, ...]
  }
}
```

**3. artifact.meta.json (M√°quina)**
```json
{
  "provenance": {
    "original_file": "path/to/original",
    "sha256": "hash_do_original",
    "captured_at": "2025-01-15T09:00:00Z",
    "processed_at": "2025-01-15T10:30:00Z"
  },
  "processing": {
    "hub_version": "2.0",
    "skills_used": [
      {"name": "synthesizer", "version": "1.2", "duration_ms": 450},
      {"name": "tokenizer", "version": "1.0", "duration_ms": 120},
      {"name": "purpose_extractor", "version": "0.9", "duration_ms": 230},
      {"name": "qa_generator", "version": "1.1", "duration_ms": 890},
      {"name": "evaluator", "version": "1.0", "duration_ms": 340}
    ],
    "total_duration_ms": 2030
  },
  "taxonomy": {
    "domain": "ai-ml",
    "entity": "transformer",
    "purpose": ["education", "reference"],
    "confidence": 0.88
  },
  "quality": {
    "score": 0.92,
    "dimensions": {
      "clarity": 0.95,
      "completeness": 0.90,
      "accuracy": 0.91
    }
  },
  "relationships": {
    "similar_to": ["hash1", "hash2"],
    "references": ["hash3"],
    "referenced_by": []
  }
}
```

---

### 6. TRONCO (‚àû) - ORQUESTRA√á√ÉO

#### 6.1 Filosofia

> "Tronco bombeia seiva. N√£o sabe se vai chover. S√≥ faz seu trabalho."

**Responsabilidades:**
- Receber requests
- Chamar Skills
- Coordenar workflows
- Monitorar tudo
- Aprender com feedback

#### 6.2 Core.py (Orquestrador)

```python
"""
core.py - Cora√ß√£o do Sistema LCM-AI
"""

import yaml
import json
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

# Imports dos Skills
from skills.skill_synthesizer import synthesize
from skills.skill_tokenizer import tokenize
from skills.skill_purpose_extractor import extract_purpose
from skills.skill_qa_generator import generate_qa
from skills.skill_evaluator import evaluate

class LCMCore:
    """
    Orquestrador central do sistema LCM-AI.
    Coordena Skills, gerencia estado, aprende com feedback.
    """
    
    def __init__(self, config_path: str = "00_‚àû_hub/config.yaml"):
        self.config = self.load_config(config_path)
        self.monitoring_log = Path("00_‚àû_hub/monitoring.jsonl")
        
    def load_config(self, path: str) -> Dict:
        """Carrega configura√ß√£o e pesos"""
        with open(path) as f:
            return yaml.safe_load(f)
    
    def process_document(self, doc_path: str) -> Dict:
        """
        Pipeline completo: documento ‚Üí Trinity
        
        Args:
            doc_path: Caminho do documento original
            
        Returns:
            Dict com paths dos artefatos gerados
        """
        start_time = datetime.now()
        
        # 1. LOAD documento original
        doc = self.load_document(doc_path)
        doc_hash = hashlib.sha256(doc.encode()).hexdigest()
        
        # 2. CAPTURE original em ‚àí01_capture/
        capture_path = self.capture_original(doc, doc_hash)
        
        # 3. SKILLS pipeline
        results = {}
        
        # Skill 1: Synthesizer (resumos Fibonacci)
        results['summaries'] = synthesize(
            doc, 
            levels=self.config['skills']['synthesizer']['levels']
        )
        
        # Skill 2: Tokenizer (chunks Fibonacci)
        results['chunks'] = tokenize(
            doc,
            sizes=self.config['skills']['tokenizer']['sizes']
        )
        
        # Skill 3: Purpose Extractor (TUO: domain/entity/purpose)
        results['taxonomy'] = extract_purpose(
            doc,
            vocab=self.config['taxonomy']
        )
        
        # Skill 4: Q&A Generator
        results['qa_pairs'] = generate_qa(
            doc,
            n_questions=self.config['skills']['qa_generator']['n_questions']
        )
        
        # Skill 5: Evaluator (score de qualidade)
        results['quality'] = evaluate(
            doc,
            criteria=self.config['skills']['evaluator']['criteria']
        )
        
        # 4. EMITIR Trinity
        trinity_paths = self.emit_trinity(
            doc_hash=doc_hash,
            original_path=capture_path,
            content=doc,
            results=results
        )
        
        # 5. INDEXAR
        self.index_artifact(doc_hash, results['taxonomy'], trinity_paths)
        
        # 6. CRIAR SYMLINKS em views/
        self.create_views(doc_hash, results['taxonomy'], trinity_paths)
        
        # 7. LOG monitoramento
        duration = (datetime.now() - start_time).total_seconds()
        self.log_processing(doc_hash, results, duration)
        
        return {
            'hash': doc_hash,
            'trinity': trinity_paths,
            'quality': results['quality'],
            'duration_s': duration
        }
    
    def emit_trinity(
        self, 
        doc_hash: str, 
        original_path: str,
        content: str, 
        results: Dict
    ) -> Dict[str, str]:
        """
        Gera os 3 arquivos: .md, .llm.json, .meta.json
        """
        taxonomy = results['taxonomy']
        base_path = Path(
            f"‚àí02_build/{taxonomy['domain']}/"
            f"{taxonomy['entity']}/{taxonomy['purpose'][0]}"
        )
        base_path.mkdir(parents=True, exist_ok=True)
        
        artifact_name = f"{doc_hash[:12]}"
        
        # 1. artifact.md (Humano)
        md_path = base_path / f"{artifact_name}.md"
        with open(md_path, 'w') as f:
            f.write(self.format_md(content, results))
        
        # 2. artifact.llm.json (IA)
        llm_path = base_path / f"{artifact_name}.llm.json"
        with open(llm_path, 'w') as f:
            json.dump(self.format_llm_json(doc_hash, content, results), f, indent=2)
        
        # 3. artifact.meta.json (M√°quina)
        meta_path = base_path / f"{artifact_name}.meta.json"
        with open(meta_path, 'w') as f:
            json.dump(self.format_meta_json(
                doc_hash, original_path, results
            ), f, indent=2)
        
        return {
            'md': str(md_path),
            'llm_json': str(llm_path),
            'meta_json': str(meta_path)
        }
    
    def log_processing(self, doc_hash: str, results: Dict, duration: float):
        """
        Append ao monitoring.jsonl para aprendizado
        """
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'doc_hash': doc_hash,
            'quality_score': results['quality']['score'],
            'taxonomy': results['taxonomy'],
            'duration_s': duration,
            'skills_performance': {
                skill: results.get(f'{skill}_time', 0)
                for skill in ['synthesizer', 'tokenizer', 'purpose_extractor', 
                             'qa_generator', 'evaluator']
            }
        }
        
        with open(self.monitoring_log, 'a') as f:
            f.write(json.dumps(log_entry) + '\n')
    
    def learn_from_feedback(self, doc_hash: str, feedback: Dict):
        """
        Ajusta pesos baseado em feedback do usu√°rio
        
        Args:
            doc_hash: ID do artefato
            feedback: {'rating': 1-5, 'comments': str, 'aspect': str}
        """
        # Carrega hist√≥rico de feedback
        feedback_log = Path("+08_feedback/feedback.jsonl")
        
        # Registra feedback
        feedback_entry = {
            'timestamp': datetime.now().isoformat(),
            'doc_hash': doc_hash,
            'feedback': feedback
        }
        
        with open(feedback_log, 'a') as f:
            f.write(json.dumps(feedback_entry) + '\n')
        
        # Atualiza pesos se necess√°rio
        if feedback['rating'] <= 2:  # Feedback negativo
            self.adjust_weights(feedback['aspect'], direction='down')
        elif feedback['rating'] >= 4:  # Feedback positivo
            self.adjust_weights(feedback['aspect'], direction='up')
        
    def adjust_weights(self, aspect: str, direction: str):
        """
        Ajusta pesos em config.yaml
        """
        adjustment = 0.05 if direction == 'up' else -0.05
        
        # Mapeamento aspecto ‚Üí skill
        skill_map = {
            'summary': 'synthesizer',
            'chunking': 'tokenizer',
            'taxonomy': 'purpose_extractor',
            'questions': 'qa_generator',
            'quality': 'evaluator'
        }
        
        skill = skill_map.get(aspect)
        if skill:
            current_weight = self.config['skills'][skill].get('weight', 1.0)
            new_weight = max(0.1, min(2.0, current_weight + adjustment))
            self.config['skills'][skill]['weight'] = new_weight
            
            # Salva config atualizado
            with open("00_‚àû_hub/config.yaml", 'w') as f:
                yaml.dump(self.config, f)
```

#### 6.3 Config.yaml (Pesos e Par√¢metros)

```yaml
# config.yaml - Configura√ß√£o Central do Sistema

system:
  version: "2.0"
  hub: "00_‚àû_hub"
  monitoring: true

skills:
  synthesizer:
    enabled: true
    weight: 1.0
    levels: [1, 2, 3, 5, 8]  # Fibonacci
    strategy: "progressive"
    
  tokenizer:
    enabled: true
    weight: 1.0
    sizes: [128, 256, 384, 640, 1024]  # Fibonacci-ish
    overlap: 0.1
    
  purpose_extractor:
    enabled: true
    weight: 1.2  # Peso maior = mais importante
    method: "tfidf"
    top_k: 10
    
  qa_generator:
    enabled: true
    weight: 0.9
    n_questions: 5
    types: ["what", "how", "why", "when", "example"]
    
  evaluator:
    enabled: true
    weight: 1.0
    criteria:
      clarity: 0.3
      completeness: 0.3
      accuracy: 0.4

taxonomy:
  domains:
    - ai-ml
    - software-eng
    - business
    - science
    - personal
  
  entities:
    # Auto-expandido via TF-IDF
    min_confidence: 0.7
  
  purposes:
    - education
    - reference
    - tutorial
    - specification
    - research

routing:
  # Decis√£o de qual workflow usar
  threshold_quality: 0.7
  threshold_length: 5000  # tokens
  
  workflows:
    simple:
      condition: "length < 1000 AND type == 'note'"
      skills: ["synthesizer", "evaluator"]
    
    standard:
      condition: "default"
      skills: ["synthesizer", "tokenizer", "purpose_extractor", 
               "qa_generator", "evaluator"]
    
    complex:
      condition: "length > 5000 OR type == 'paper'"
      skills: ["synthesizer", "tokenizer", "purpose_extractor", 
               "qa_generator", "evaluator", "citation_extractor"]

feedback:
  enabled: true
  learning_rate: 0.05
  adjustment_threshold: 3  # M√≠nimo de feedbacks para ajustar

monitoring:
  log_path: "00_‚àû_hub/monitoring.jsonl"
  metrics:
    - duration
    - quality_score
    - skill_performance
  retention_days: 90
```

---

### 7. GALHOS (+) - DISTRIBUI√á√ÉO

#### 7.1 Filosofia

> "Galhos crescem pro c√©u. Cada um independente. Todos paralelos."

**Responsabilidades:**
- Receber requests (+01_intake)
- Rotear inteligentemente (+02_route)
- Executar workflows (+03_execute)
- Entregar resultados (+05_delivery)
- Coletar feedback (+08_feedback)

#### 7.2 Camadas de Galhos

##### +01_intake/ (Porta de Entrada)
```python
"""
Recebe documentos via m√∫ltiplos canais
"""

class IntakeManager:
    """Gerencia entrada de documentos"""
    
    channels = {
        'upload': 'Via UI web',
        'api': 'REST API /api/upload',
        'email': 'Email parsing',
        'webhook': 'Integra√ß√µes externas',
        'filesystem': 'Watch folder'
    }
    
    def receive(self, source: str, payload: bytes) -> str:
        """
        Recebe documento, valida, enfileira
        
        Returns:
            job_id para tracking
        """
        # Valida√ß√£o b√°sica
        if len(payload) > 100_000_000:  # 100MB
            raise ValueError("File too large")
        
        # Criar job
        job_id = self.create_job(source, payload)
        
        # Enfileirar para processamento
        self.queue.put(job_id)
        
        return job_id
```

##### +02_route/ (Roteamento Inteligente)
```python
"""
Decide qual workflow executar
"""

class Router:
    """Roteamento baseado em caracter√≠sticas do documento"""
    
    def route(self, doc_meta: Dict) -> str:
        """
        Decide workflow baseado em metadados
        
        Returns:
            workflow_name
        """
        # Scoring multi-dimensional
        scores = {
            'simple': self.score_simple(doc_meta),
            'standard': self.score_standard(doc_meta),
            'complex': self.score_complex(doc_meta)
        }
        
        # Escolhe workflow com maior score
        return max(scores, key=scores.get)
    
    def score_simple(self, meta: Dict) -> float:
        """Score para workflow simples"""
        score = 0.0
        
        if meta['length_tokens'] < 1000:
            score += 0.5
        
        if meta['type'] in ['note', 'snippet']:
            score += 0.3
        
        if meta.get('priority') == 'low':
            score += 0.2
        
        return score
```

##### +03_execute/ (Execu√ß√£o)
```python
"""
Executa workflows (futuramente paralelo)
"""

class WorkflowExecutor:
    """Executa workflows definidos"""
    
    def execute(self, job_id: str, workflow: str):
        """
        Executa workflow espec√≠fico
        """
        # Carrega documento
        doc = self.load_job(job_id)
        
        # Executa baseado em workflow
        if workflow == 'simple':
            result = self.run_simple(doc)
        elif workflow == 'standard':
            result = self.run_standard(doc)
        elif workflow == 'complex':
            result = self.run_complex(doc)
        
        # Publica resultado
        self.publish_result(job_id, result)
        
        return result
    
    def run_standard(self, doc: str) -> Dict:
        """Workflow padr√£o (todos skills)"""
        core = LCMCore()
        return core.process_document(doc)
```

##### +05_delivery/ (Entrega)
```python
"""
Disponibiliza resultados
"""

class DeliveryManager:
    """Gerencia entrega de artefatos"""
    
    def deliver(self, job_id: str, format: str = 'json'):
        """
        Entrega resultado em formato solicitado
        
        Args:
            job_id: ID do job
            format: 'json' | 'markdown' | 'html' | 'pdf'
        """
        # Carrega Trinity
        trinity = self.load_trinity(job_id)
        
        # Formata conforme solicitado
        if format == 'json':
            return trinity['llm_json']
        elif format == 'markdown':
            return trinity['md']
        elif format == 'html':
            return self.md_to_html(trinity['md'])
        elif format == 'pdf':
            return self.md_to_pdf(trinity['md'])
```

##### +08_feedback/ (Aprendizado)
```python
"""
Coleta e processa feedback
"""

class FeedbackCollector:
    """Gerencia feedback loop"""
    
    def collect(self, job_id: str, rating: int, comment: str):
        """
        Registra feedback e aciona aprendizado
        """
        core = LCMCore()
        
        feedback = {
            'rating': rating,  # 1-5
            'comment': comment,
            'aspect': self.infer_aspect(comment)
        }
        
        # LCMCore aprende e ajusta pesos
        core.learn_from_feedback(job_id, feedback)
    
    def infer_aspect(self, comment: str) -> str:
        """
        Infere qual aspecto do sistema precisa melhorar
        """
        keywords = {
            'summary': ['resumo', 's√≠ntese', 'TL;DR'],
            'chunking': ['chunks', 'divis√£o', 'tamanho'],
            'taxonomy': ['categoriza√ß√£o', 'tags', 'organiza√ß√£o'],
            'questions': ['perguntas', 'Q&A'],
            'quality': ['qualidade', 'ruim', 'excelente']
        }
        
        for aspect, kws in keywords.items():
            if any(kw in comment.lower() for kw in kws):
                return aspect
        
        return 'general'
```

---

### 8. FOLHAS (SKILLS) - TRANSFORMA√á√ÉO

#### 8.1 Filosofia

> "Folhas parecem passivas. Mas fazem fotoss√≠ntese: CO2 + luz ‚Üí a√ß√∫car = vida"

**Princ√≠pios dos Skills:**
- ‚úÖ Fun√ß√£o pura (input ‚Üí output, sem side effects)
- ‚úÖ Uma responsabilidade
- ‚úÖ Compos√≠vel
- ‚úÖ Test√°vel isoladamente

#### 8.2 As 5 Folhas do Sistema

##### Skill 1: Synthesizer (Resumos Fibonacci)

```python
"""
skill_synthesizer.py - Gera resumos em progress√£o Fibonacci
"""

def synthesize(text: str, levels: List[int] = [1, 2, 3, 5, 8]) -> Dict[int, str]:
    """
    Gera resumos em m√∫ltiplos n√≠veis de detalhe.
    
    Args:
        text: Documento completo
        levels: N√≠veis Fibonacci de linhas
        
    Returns:
        Dict mapeando n√≠vel ‚Üí resumo
        
    Example:
        >>> doc = "Long document..."
        >>> summaries = synthesize(doc)
        >>> summaries[1]
        "One-line essence of the document"
        >>> summaries[8]
        "Eight-line comprehensive summary with context, 
         key points, implications, and next steps..."
    """
    summaries = {}
    
    for n_lines in levels:
        prompt = f"""
        Resuma o texto abaixo em EXATAMENTE {n_lines} linha(s).
        
        Regras:
        - Cada linha deve ser completa (terminar com ponto)
        - Progress√£o: mais linhas = mais detalhe, n√£o repeti√ß√£o
        - {n_lines} linha(s): {"ess√™ncia" if n_lines == 1 else "contexto progressivo"}
        
        Texto:
        {text}
        
        Resumo em {n_lines} linha(s):
        """
        
        # Chama LLM (abstra√ß√£o)
        summary = call_llm(prompt, max_tokens=n_lines * 50)
        
        summaries[n_lines] = summary.strip()
    
    return summaries
```

##### Skill 2: Tokenizer (Chunks Fibonacci)

```python
"""
skill_tokenizer.py - Divide em chunks de tamanhos Fibonacci
"""

import tiktoken

def tokenize(
    text: str, 
    sizes: List[int] = [128, 256, 384, 640, 1024],
    overlap: float = 0.1
) -> Dict[int, List[str]]:
    """
    Divide texto em chunks de diferentes tamanhos.
    
    Args:
        text: Documento completo
        sizes: Tamanhos em tokens (Fibonacci-ish)
        overlap: % de overlap entre chunks (padr√£o 10%)
        
    Returns:
        Dict mapeando tamanho ‚Üí lista de chunks
        
    Example:
        >>> text = "Very long document..."
        >>> chunks = tokenize(text, sizes=[128, 256])
        >>> len(chunks[128])
        10  # 10 chunks de 128 tokens
        >>> len(chunks[256])
        5   # 5 chunks de 256 tokens (menos chunks, mais contexto)
    """
    enc = tiktoken.get_encoding("cl100k_base")
    tokens = enc.encode(text)
    
    all_chunks = {}
    
    for chunk_size in sizes:
        stride = int(chunk_size * (1 - overlap))
        chunks_for_size = []
        
        for i in range(0, len(tokens), stride):
            chunk_tokens = tokens[i:i + chunk_size]
            
            if len(chunk_tokens) < chunk_size // 2:
                # Chunk muito pequeno no final, ignora
                break
            
            chunk_text = enc.decode(chunk_tokens)
            chunks_for_size.append(chunk_text)
        
        all_chunks[chunk_size] = chunks_for_size
    
    return all_chunks
```

##### Skill 3: Purpose Extractor (TUO: Domain/Entity/Purpose)

```python
"""
skill_purpose_extractor.py - Extrai taxonomia via TF-IDF + LLM
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from typing import Dict, List

def extract_purpose(
    text: str,
    vocab: Dict[str, List[str]]
) -> Dict[str, any]:
    """
    Extrai Domain, Entity, Purpose (TUO).
    
    Args:
        text: Documento
        vocab: Taxonomia de dom√≠nios/purposes conhecidos
        
    Returns:
        {
            'domain': 'ai-ml',
            'entity': 'transformer',
            'purpose': ['education', 'reference'],
            'confidence': 0.88,
            'keywords': ['attention', 'self-attention', 'encoder', ...]
        }
    """
    # 1. TF-IDF para keywords
    vectorizer = TfidfVectorizer(max_features=50, stop_words='english')
    tfidf_matrix = vectorizer.fit_transform([text])
    feature_names = vectorizer.get_feature_names_out()
    
    # Top-10 keywords por TF-IDF score
    scores = tfidf_matrix.toarray()[0]
    top_indices = scores.argsort()[-10:][::-1]
    keywords = [feature_names[i] for i in top_indices]
    
    # 2. LLM para Domain/Entity/Purpose
    prompt = f"""
    Analise o texto e classifique:
    
    **Domain** (escolha 1): {', '.join(vocab['domains'])}
    **Entity** (palavra-chave principal, m√°x 3 palavras)
    **Purpose** (escolha 1-3): {', '.join(vocab['purposes'])}
    
    Keywords detectados: {', '.join(keywords)}
    
    Texto (primeiras 500 palavras):
    {' '.join(text.split()[:500])}
    
    Responda em JSON:
    {{
        "domain": "...",
        "entity": "...",
        "purpose": ["...", "..."],
        "confidence": 0.0-1.0
    }}
    """
    
    result = call_llm(prompt, response_format="json")
    taxonomy = parse_json(result)
    taxonomy['keywords'] = keywords
    
    return taxonomy
```

##### Skill 4: Q&A Generator

```python
"""
skill_qa_generator.py - Gera perguntas e respostas autom√°ticas
"""

def generate_qa(
    text: str,
    n_questions: int = 5,
    types: List[str] = ["what", "how", "why", "when", "example"]
) -> List[Dict[str, str]]:
    """
    Gera pares Q&A para compreens√£o.
    
    Args:
        text: Documento
        n_questions: N√∫mero de perguntas
        types: Tipos de perguntas
        
    Returns:
        [
            {"question": "What is X?", "answer": "X is..."},
            {"question": "How does Y work?", "answer": "Y works by..."}
        ]
    """
    qa_pairs = []
    
    for q_type in types[:n_questions]:
        prompt = f"""
        Baseado no texto abaixo, gere 1 pergunta do tipo "{q_type.upper()}"
        e sua resposta completa.
        
        Formato:
        Q: [pergunta clara e espec√≠fica]
        A: [resposta completa em 2-3 senten√ßas]
        
        Texto:
        {text}
        
        Q&A:
        """
        
        response = call_llm(prompt, max_tokens=200)
        
        # Parse Q: e A:
        lines = response.strip().split('\n')
        question = lines[0].replace('Q:', '').strip()
        answer = '\n'.join(lines[1:]).replace('A:', '').strip()
        
        qa_pairs.append({
            'question': question,
            'answer': answer,
            'type': q_type
        })
    
    return qa_pairs
```

##### Skill 5: Evaluator

```python
"""
skill_evaluator.py - Avalia qualidade do documento/processamento
"""

def evaluate(
    text: str,
    criteria: Dict[str, float] = {
        'clarity': 0.3,
        'completeness': 0.3,
        'accuracy': 0.4
    }
) -> Dict[str, float]:
    """
    Avalia qualidade em m√∫ltiplas dimens√µes.
    
    Args:
        text: Documento
        criteria: Pesos para cada crit√©rio
        
    Returns:
        {
            'score': 0.92,  # Score agregado
            'dimensions': {
                'clarity': 0.95,
                'completeness': 0.90,
                'accuracy': 0.91
            },
            'confidence': 0.88
        }
    """
    prompt = f"""
    Avalie o texto abaixo em 3 dimens√µes (0-1):
    
    1. **Clarity** (Clareza): Linguagem clara? F√°cil entender?
    2. **Completeness** (Completude): Cobre o t√≥pico adequadamente?
    3. **Accuracy** (Precis√£o): Informa√ß√£o parece correta?
    
    Texto (primeiras 1000 palavras):
    {' '.join(text.split()[:1000])}
    
    Responda APENAS em JSON:
    {{
        "clarity": 0.0-1.0,
        "completeness": 0.0-1.0,
        "accuracy": 0.0-1.0,
        "confidence": 0.0-1.0
    }}
    """
    
    response = call_llm(prompt, response_format="json")
    dimensions = parse_json(response)
    
    # Score agregado (weighted average)
    score = sum(
        dimensions[dim] * weight
        for dim, weight in criteria.items()
    )
    
    return {
        'score': round(score, 3),
        'dimensions': dimensions,
        'confidence': dimensions.get('confidence', 0.8)
    }
```

---

### 9. FRUTO (13) - APLICA√á√ïES

#### 9.1 Filosofia

> "√Årvore faz fruto. Fruto cai. Algu√©m come. Semente nasce. Tudo recome√ßa."

**Caracter√≠sticas:**
- ‚úÖ Desacoplado da √°rvore
- ‚úÖ Consome via API
- ‚úÖ M√∫ltiplos "sabores" (web, mobile, CLI)
- ‚úÖ Agn√≥stico de implementa√ß√£o interna

#### 9.2 Interfaces de Consumo

##### REST API

```python
"""
API REST para consumo externo
"""

from fastapi import FastAPI, UploadFile
from lcm_core import LCMCore

app = FastAPI()
core = LCMCore()

@app.post("/api/upload")
async def upload_document(file: UploadFile):
    """
    Recebe documento, processa, retorna job_id
    """
    content = await file.read()
    
    # Salva em +01_intake/
    job_id = save_to_intake(content, file.filename)
    
    # Enfileira processamento
    queue_processing(job_id)
    
    return {"job_id": job_id, "status": "queued"}

@app.get("/api/status/{job_id}")
def get_status(job_id: str):
    """
    Verifica status do processamento
    """
    status = check_job_status(job_id)
    return {"job_id": job_id, "status": status}

@app.get("/api/result/{job_id}")
def get_result(job_id: str, format: str = "json"):
    """
    Retorna resultado em formato solicitado
    """
    delivery = DeliveryManager()
    result = delivery.deliver(job_id, format)
    return result

@app.get("/api/search")
def search(q: str, limit: int = 10):
    """
    Busca sem√¢ntica nos artefatos
    """
    from search_engine import search_artifacts
    results = search_artifacts(q, limit=limit)
    return {"results": results}

@app.post("/api/feedback/{job_id}")
def submit_feedback(job_id: str, rating: int, comment: str):
    """
    Envia feedback para aprendizado
    """
    feedback_collector = FeedbackCollector()
    feedback_collector.collect(job_id, rating, comment)
    return {"status": "feedback_received"}
```

##### Web Interface (Exemplo conceitual)

```javascript
// Frontend consome API REST

class LCMClient {
    constructor(apiUrl = 'http://localhost:8000') {
        this.apiUrl = apiUrl;
    }
    
    async upload(file) {
        const formData = new FormData();
        formData.append('file', file);
        
        const response = await fetch(`${this.apiUrl}/api/upload`, {
            method: 'POST',
            body: formData
        });
        
        return await response.json();
    }
    
    async getResult(jobId, format = 'json') {
        const response = await fetch(
            `${this.apiUrl}/api/result/${jobId}?format=${format}`
        );
        return await response.json();
    }
    
    async search(query) {
        const response = await fetch(
            `${this.apiUrl}/api/search?q=${encodeURIComponent(query)}`
        );
        return await response.json();
    }
}

// Uso
const client = new LCMClient();

// Upload
const file = document.getElementById('fileInput').files[0];
const {job_id} = await client.upload(file);

// Poll status
const checkStatus = setInterval(async () => {
    const {status} = await client.getStatus(job_id);
    if (status === 'completed') {
        clearInterval(checkStatus);
        const result = await client.getResult(job_id);
        displayResult(result);
    }
}, 2000);
```

---

## PARTE III: WORKFLOWS DE AGENTES

### 10. FRAMEWORK GEN√âRICO DE AGENTES

#### 10.1 Arquitetura de 3 Agentes

**Workflow padr√£o para cria√ß√£o de conte√∫do:**

```
AGENTE 1: RESEARCH_NOTES
(Pesquisa + Intelligence)
        ‚Üì
   Output: research_notes.md
        ‚Üì
AGENTE 2: COPY_GENERATOR
(Reda√ß√£o + Estrutura√ß√£o)
        ‚Üì
   Output: copy_pack.json
        ‚Üì
AGENTE 3: IMAGE_GENERATOR
(Cria√ß√£o Visual)
        ‚Üì
   Output: image_grid_3x3
        ‚Üì
    ENTREGA FINAL
```

#### 10.2 Properties Comuns

Cada agente segue estrutura padr√£o:

```yaml
agent:
  name: "agent_name"
  version: "X.Y.Z"
  owner: "BRAND ¬∑ LCM-AI"
  language: "pt-BR"
  visibility: "internal|public"
  task_type: "research|copy|visual|analysis"
  requires:
    - file_search
    - web_search
    - logging
```

#### 10.3 Fluxo de Dados Entre Agentes

```python
class AgentPipeline:
    """
    Orquestra workflow de m√∫ltiplos agentes
    """
    
    def __init__(self):
        self.agent1 = ResearchAgent()
        self.agent2 = CopyAgent()
        self.agent3 = VisualAgent()
    
    def execute(self, brief: Dict) -> Dict:
        """
        Executa pipeline completo
        
        Args:
            brief: {
                'produto': 'Nome do produto',
                'marca': 'Marca',
                'categoria': 'Categoria',
                'publico_alvo': 'Descri√ß√£o',
                'marketplaces': ['mercadolivre', 'amazon'],
                'imagens_ref': ['url1', 'url2']
            }
            
        Returns:
            {
                'research': research_notes,
                'copy': copy_pack,
                'images': image_grid,
                'qa_report': validations
            }
        """
        # STAGE 1: Research
        research_notes = self.agent1.research(brief)
        
        # STAGE 2: Copy (usa research)
        copy_pack = self.agent2.generate_copy(
            brief=brief,
            research_notes=research_notes
        )
        
        # STAGE 3: Visual (usa research + copy)
        image_grid = self.agent3.generate_visuals(
            brief=brief,
            research_notes=research_notes,
            copy_pack=copy_pack
        )
        
        # VALIDATION
        qa_report = self.validate_outputs(
            research_notes,
            copy_pack,
            image_grid
        )
        
        return {
            'research': research_notes,
            'copy': copy_pack,
            'images': image_grid,
            'qa': qa_report
        }
```

---

### 11. AGENTE 1: RESEARCH & INTELLIGENCE

[Conte√∫do completo do AGENTE 1 do documento AGENTES_AI_WORKFLOW_GENERICO.md]

#### 11.1 Papel e Objetivo

**Papel:** Pesquisador t√°tico de marketplaces. Especialista em SEO e heur√≠sticas de linguagem.

**Objetivo:** Consolidar insumos para planejamento de an√∫ncio. N√ÉO gere copy nesta etapa.

#### 11.2 Metodologia (Ordem Obrigat√≥ria)

```python
class ResearchAgent:
    """Agente 1: Pesquisa e Intelligence"""
    
    def research(self, brief: Dict) -> str:
        """
        Executa pesquisa completa
        
        Returns:
            research_notes.md (formato estruturado)
        """
        steps = [
            self.validate_brief,
            self.generate_head_terms,
            self.derive_longtails,
            self.web_search_inbound,
            self.web_search_outbound,
            self.benchmark_competitors,
            self.analyze_gaps
        ]
        
        results = {}
        for step in steps:
            results[step.__name__] = step(brief, results)
        
        # Gera research_notes.md
        return self.format_research_notes(results)
    
    def generate_head_terms(self, brief: Dict, results: Dict) -> List[str]:
        """
        Gera termos principais de busca
        """
        produto = brief['produto']
        beneficio = brief.get('beneficio_principal', '')
        atributos = brief.get('atributos', [])
        
        terms = [
            produto,
            f"{produto} {beneficio}",
            f"{produto} {atributos[0]}" if atributos else produto
        ]
        
        return terms
    
    def web_search_inbound(self, brief: Dict, results: Dict) -> Dict:
        """
        Busca em marketplaces
        """
        head_terms = results['generate_head_terms']
        marketplaces = brief['marketplaces']
        
        findings = {}
        
        for marketplace in marketplaces:
            for term in head_terms:
                query = f'site:{marketplace}.com.br "{term}"'
                search_results = web_search(query)
                
                findings[f"{marketplace}_{term}"] = {
                    'patterns': extract_title_patterns(search_results),
                    'price_range': extract_price_range(search_results),
                    'common_claims': extract_claims(search_results)
                }
        
        return findings
```

[... continuar com todas as se√ß√µes do workflow de agentes ...]

---

## PARTE IV: HIERARQUIA CLAUDE CODE

### 15. CORE-4: CONTEXTO, MODELOS, PROMPT, FERRAMENTAS

#### 15.1 Princ√≠pio Fundamental

> **"The prompt is the new fundamental unit of knowledge work"**

Todo sistema Claude Code √© constru√≠do sobre 4 pilares:

```
    CONTEXTO
       ‚Üì
    MODELOS ‚Üê‚Üí PROMPT ‚Üê‚Üí FERRAMENTAS
```

**1. CONTEXTO** (Single Source of Truth)
```yaml
# context/theme.yml
project: "Nome do Projeto"
brand:
  palette: ["#111111", "#f5f5f5"]
  style: ["minimal", "editorial"]
goals:
  - objetivo_1
  - objetivo_2
constraints:
  - restricao_1
  - restricao_2
```

**2. MODELOS** (Pap√©is)
- **Orchestrator**: Claude Code coordena
- **Specialists**: Subagents especializados
- **Tools**: MCPs para integra√ß√µes

**3. PROMPT** (Instru√ß√µes)
- Slash Commands: primitivos at√¥micos
- System Prompts: contexto persistente
- Few-shot Examples: aprendizado por exemplo

**4. FERRAMENTAS** (Capacidades)
- Bash, Python, APIs
- File system, Git
- MCPs customizados

---

### 16. SLASH COMMANDS (PRIMITIVOS)

#### 16.1 Filosofia

**Slash Commands s√£o:**
- ‚úÖ At√¥micos (uma a√ß√£o)
- ‚úÖ Determin√≠sticos (mesmo input ‚Üí mesmo output)
- ‚úÖ Compos√≠veis (podem ser combinados)
- ‚úÖ Versionados (evolu√ß√£o controlada)

#### 16.2 Estrutura de Comando

```markdown
# ~/.claude/commands/category/command-name.md

## Objetivo
[Uma linha descrevendo o que faz]

## Entradas
- `param1`: Descri√ß√£o (tipo, exemplo)
- `param2`: Descri√ß√£o (tipo, exemplo)

## Sa√≠das
[Formato exato do output - JSON/YAML/Markdown]

## Exemplo
```bash
/category/command-name param1="valor" param2="valor"
```

## Output Exemplo
```json
{
  "result": "...",
  "metadata": {...}
}
```

## Valida√ß√£o
- [ ] Checklist 1
- [ ] Checklist 2

## Notas
[Considera√ß√µes adicionais]
```

#### 16.3 Exemplos de Slash Commands

##### /theme/shotlist
```markdown
# ~/.claude/commands/theme/shotlist.md

## Objetivo
Gerar lista de 9 cenas fotogr√°ficas baseado em context/theme.yml

## Entradas
- `theme_path`: Caminho para context/theme.yml
- `n_shots`: N√∫mero de cenas (padr√£o: 9)

## Sa√≠das
JSON array com estrutura por cena:
```json
[
  {
    "id": "S1",
    "goal": "hero",
    "composition": "produto 85%+ do frame",
    "lens": "50mm",
    "lighting": "softbox difusa 45¬∞",
    "background": "branco",
    "risks": ["texto", "reflexo"]
  }
]
```

## Valida√ß√£o
- [ ] Exatamente n_shots cenas
- [ ] Cada cena tem todos campos obrigat√≥rios
- [ ] IDs sequenciais (S1, S2, ...)
- [ ] Risks identificados
```

##### /qa/validate-output
```markdown
# ~/.claude/commands/qa/validate-output.md

## Objetivo
Validar outputs contra especifica√ß√£o

## Entradas
- `output_path`: Caminho do arquivo gerado
- `spec_path`: Caminho da especifica√ß√£o
- `type`: Tipo de valida√ß√£o ('image'|'copy'|'data')

## Sa√≠das
```json
{
  "valid": true|false,
  "checks": [
    {"check": "nome_check", "passed": true|false, "details": "..."}
  ],
  "score": 0.0-1.0,
  "notes": "..."
}
```

## Exemplo
```bash
/qa/validate-output output_path="dist/image1.png" spec_path="context/theme.yml" type="image"
```
```

---

### 17. SUBAGENTS (ESPECIALIZA√á√ÉO)

#### 17.1 Quando Usar Subagent

**Use Subagent quando:**
- ‚úÖ Tarefa requer especializa√ß√£o profunda
- ‚úÖ Necess√°rio isolamento de contexto
- ‚úÖ Paraleliza√ß√£o de trabalho
- ‚úÖ M√∫ltiplas itera√ß√µes com memoria pr√≥pria

**N√ÉO use Subagent quando:**
- ‚ùå Tarefa √© at√¥mica (use Slash Command)
- ‚ùå N√£o requer especializa√ß√£o
- ‚ùå L√≥gica j√° existe em outro lugar

#### 17.2 Estrutura de Subagent

```
subagents/nome-subagent/
  README.md              # Documenta√ß√£o
  system_prompt.md       # Prompt especializado
  context/               # Contexto espec√≠fico
  tools/                 # Ferramentas auxiliares
  examples/              # Exemplos de I/O
```

#### 17.3 Exemplo: Art Director Subagent

```markdown
# subagents/art-director/README.md

## Papel
Cr√≠tico visual especializado em valida√ß√£o de imagens para marketplace

## Responsabilidades
1. Validar composi√ß√£o (regra dos ter√ßos, balance)
2. Checar consist√™ncia de paleta
3. Identificar artefatos/glitches
4. Verificar compliance (sem texto, watermarks)
5. Sugerir ajustes espec√≠ficos

## Inputs
- `image_path`: Caminho da imagem
- `spec`: Especifica√ß√£o visual (de context/theme.yml)
- `shot_id`: ID da cena (S1-S9)

## Outputs
```json
{
  "shot_id": "S1",
  "verdict": "pass"|"needs_adjustment"|"fail",
  "scores": {
    "composition": 0.0-1.0,
    "lighting": 0.0-1.0,
    "palette_consistency": 0.0-1.0,
    "technical_quality": 0.0-1.0
  },
  "issues": [
    {"severity": "critical"|"warning", "description": "..."}
  ],
  "suggestions": [
    "Sugest√£o espec√≠fica de melhoria"
  ]
}
```

## Invoca√ß√£o
```python
# Via Claude Code
result = subagent.art_director.review(
    image_path="dist/S1.png",
    spec=theme_spec,
    shot_id="S1"
)
```

## Especializa√ß√£o
- Treinado em princ√≠pios de fotografia de produto
- Conhece constraints de marketplaces (ML, Amazon, etc)
- Refer√™ncia em lighting ratios (key:fill)
- Expert em detec√ß√£o de artefatos de IA generativa
```

---

### 18. MCP (MODEL CONTEXT PROTOCOL)

#### 18.1 O Que √â MCP

**MCP = Integra√ß√µes Externas**

Protocolo para conectar LLMs com:
- üóÑÔ∏è Databases (SQL, NoSQL)
- üìÅ File systems
- üåê APIs externas
- üé® Ferramentas de imagem
- üìä Dashboards
- üí¨ Chat platforms

#### 18.2 Configura√ß√£o MCP

```json
// mcp/config.json
{
  "mcpServers": {
    "image_generator": {
      "command": "python",
      "args": ["/path/to/mcp_servers/image_gen.py"],
      "env": {
        "API_KEY": "${REPLICATE_API_KEY}"
      },
      "parallel": true,
      "timeout": 300
    },
    
    "git": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-git"],
      "env": {
        "GIT_REPO_PATH": "/workspace"
      }
    },
    
    "database": {
      "command": "python",
      "args": ["/path/to/mcp_servers/postgres.py"],
      "env": {
        "DB_URL": "${DATABASE_URL}"
      }
    }
  }
}
```

#### 18.3 Exemplo: MCP de Gera√ß√£o de Imagens

```python
"""
mcp_servers/image_gen.py
MCP Server para gera√ß√£o de imagens via Replicate
"""

import json
import sys
import replicate
from typing import Dict, List

class ImageGenMCP:
    """MCP para gera√ß√£o de imagens"""
    
    def __init__(self):
        self.client = replicate.Client(api_token=os.getenv("REPLICATE_API_KEY"))
    
    def generate(self, prompts: List[Dict]) -> List[str]:
        """
        Gera imagens em paralelo
        
        Args:
            prompts: [
                {
                    "id": "S1",
                    "prompt": "product photo...",
                    "negative": "text, watermark...",
                    "width": 1024,
                    "height": 1024
                }
            ]
            
        Returns:
            List de URLs das imagens geradas
        """
        outputs = []
        
        for prompt_data in prompts:
            output = self.client.run(
                "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b",
                input={
                    "prompt": prompt_data["prompt"],
                    "negative_prompt": prompt_data["negative"],
                    "width": prompt_data["width"],
                    "height": prompt_data["height"],
                    "num_outputs": 1
                }
            )
            
            outputs.append({
                "id": prompt_data["id"],
                "url": output[0]
            })
        
        return outputs
    
    def handle_request(self, request: Dict) -> Dict:
        """Handler principal do MCP"""
        method = request.get("method")
        params = request.get("params", {})
        
        if method == "generate":
            return {
                "result": self.generate(params["prompts"])
            }
        
        return {"error": f"Unknown method: {method}"}

# MCP Server Loop
if __name__ == "__main__":
    mcp = ImageGenMCP()
    
    while True:
        line = sys.stdin.readline()
        if not line:
            break
        
        request = json.loads(line)
        response = mcp.handle_request(request)
        
        print(json.dumps(response))
        sys.stdout.flush()
```

---

### 19. SKILLS (ORQUESTRA√á√ÉO)

#### 19.1 Diferen√ßa: Skills vs Slash Commands

```
SLASH COMMAND               SKILL
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Primitivo at√¥mico          Orquestra√ß√£o
Determin√≠stico             Probabil√≠stico
Stateless                  Stateful (contexto)
Manual invocation          Agent invocation
1 a√ß√£o                     N a√ß√µes compostas
```

#### 19.2 Estrutura de Skill

```markdown
# skills/skill-name/SKILL.md

## Prop√≥sito
[Objetivo de alto n√≠vel]

## Quando Usar
- Cen√°rio 1
- Cen√°rio 2

## Capacidades
- Capacidade 1 (via ferramenta X)
- Capacidade 2 (via ferramenta Y)

## Plano de Execu√ß√£o
1. Passo 1: A√ß√£o (ferramenta)
2. Passo 2: A√ß√£o (ferramenta)
3. [...]

## Entradas Esperadas
```json
{
  "input_field": "description"
}
```

## Sa√≠das Geradas
```json
{
  "output_field": "description"
}
```

## Ferramentas Usadas
- `/slash/command`
- `subagent.name`
- `mcp.server_name.method`

## Exemplos
### Exemplo 1: [Nome]
**Input:**
```json
{...}
```

**Processo:**
1. Chama /slash/command1
2. Resultado ‚Üí subagent.specialist
3. Final ‚Üí mcp.delivery

**Output:**
```json
{...}
```
```

#### 19.3 Exemplo: Theme Builder Skill

```markdown
# skills/theme_builder/SKILL.md

## Prop√≥sito
Orquestrar cria√ß√£o completa de tema visual (PNGs + Manual) seguindo hierarquia Slash‚ÜíSubagent‚ÜíMCP‚ÜíSkill

## Quando Usar
- Criar assets visuais para produto/marca
- Gerar documenta√ß√£o visual consistente
- Produzir material de marketing

## Plano de Execu√ß√£o

### Stage 1: Planning
1. `/theme/shotlist` ‚Üí gera 9 cenas
2. Valida√ß√£o manual (opcional)
3. `/theme/image-prompts` ‚Üí converte para prompts de IA

### Stage 2: Generation
4. `mcp.image_generator.generate(prompts)` ‚Üí gera PNGs (parallel=true)
5. Aguarda conclus√£o (todas 9 imagens)

### Stage 3: Quality Assurance
6. `subagent.art_director.review(image)` para cada S1-S9 (paralelo)
7. `/qa/image` ‚Üí valida√ß√£o formal contra spec
8. Se falhas: ajustar e regenerar

### Stage 4: Documentation
9. `/theme/manual-outline` ‚Üí estrutura do manual
10. `subagent.copy_editor.write(outline)` ‚Üí rascunho completo
11. `/qa/copy` ‚Üí valida√ß√£o de texto

### Stage 5: Packaging
12. Organizar em `dist/tema-<date>/`
13. Gerar `report/qa.json`
14. Hooks automatizam: git tag, catalogar

## Sa√≠das
```
dist/tema-20250115/
  pngs/
    S1.png
    S2.png
    [...]
    S9.png
  manual/
    manual.md
    manual.pdf
  report/
    qa.json
    metrics.json
```

## Ferramentas Usadas
- Slash: `/theme/*`, `/qa/*`
- Subagents: `art-director`, `copy-editor`
- MCP: `image_generator`, `git`
- Hooks: `postRun`, `onFileEdit`
```

---

### 20. PLUGINS (EMPACOTAMENTO)

#### 20.1 O Que S√£o Plugins

**Plugin = Bundle compartilh√°vel**

Empacota:
- ‚úÖ Commands
- ‚úÖ Skills
- ‚úÖ Subagents
- ‚úÖ MCP configs
- ‚úÖ Output styles
- ‚úÖ Hooks

**Para que?**
- Compartilhar toolkit completo
- Reutilizar em m√∫ltiplos projetos
- Distribuir para comunidade

#### 20.2 Manifest de Plugin

```json
// plugin/manifest.json
{
  "name": "theme-builder",
  "version": "0.1.0",
  "description": "Complete theme builder: PNGs + Manual",
  "author": "LCM-AI",
  "license": "MIT",
  
  "includes": {
    "commands": [
      ".claude/commands/theme",
      ".claude/commands/qa"
    ],
    "skills": [
      "skills/theme_builder"
    ],
    "subagents": [
      "subagents/art-director",
      "subagents/copy-editor"
    ],
    "mcp": [
      "mcp/config.json"
    ],
    "hooks": [
      ".claude/settings.json"
    ],
    "outputStyles": [
      "output-styles/yaml-structured.md",
      "output-styles/markdown-focused.md"
    ],
    "context": [
      "context/theme.yml"
    ]
  },
  
  "dependencies": {
    "python": ">=3.8",
    "replicate": ">=0.15.0"
  },
  
  "dist": "dist/"
}
```

#### 20.3 Instala√ß√£o de Plugin

```bash
# Instalar plugin
claude plugin install theme-builder-0.1.0.tar.gz

# Lista plugins instalados
claude plugin list

# Desinstalar
claude plugin uninstall theme-builder
```

---

## PARTE V: META-CONHECIMENTO

### 21. COMO LLMS APRENDEM

[Conte√∫do do META_GUIA_DOCUMENTACAO_LLM.md - Se√ß√£o 1]

#### 21.1 Pipeline de Aprendizado

```
PRETRAINING (11T tokens)
    ‚Üì
General language understanding
    ‚Üì
SUPERVISED FINE-TUNING (10k examples)
    ‚Üì
Task-specific skills
    ‚Üì
PREFERENCE ALIGNMENT (DPO)
    ‚Üì
Human-aligned outputs
    ‚Üì
DEPLOYMENT (inference)
    ‚Üì
Real-world usage
```

#### 21.2 Mecanismo de Aten√ß√£o

```python
def attention(Q, K, V):
    """
    Q = Query (o que procuramos)
    K = Key (√≠ndices de conte√∫do)
    V = Value (conte√∫do real)
    """
    # Similaridade entre query e keys
    scores = matmul(Q, K.T) / sqrt(d_k)
    
    # Softmax ‚Üí probabilidades
    weights = softmax(scores)
    
    # Weighted sum dos values
    output = matmul(weights, V)
    
    return output
```

**Implica√ß√µes para Documenta√ß√£o:**
- Headers = Keys (√≠ndices)
- Conte√∫do = Values (recuperado)
- Dist√¢ncia importa (context window)

---

### 22. DESTILA√á√ÉO DE CONHECIMENTO

[Conte√∫do do META_GUIA sobre Knowledge Distillation]

#### 22.1 Abstraction Ladder

**Mesmo conceito, 5 n√≠veis:**

```
N√çVEL 1: MET√ÅFORA
"Imagine uma festa barulhenta..."

N√çVEL 2: CONCEITUAL
"Attention calcula import√¢ncia relativa..."

N√çVEL 3: MATEM√ÅTICO
Attention(Q,K,V) = softmax(QK^T/‚àöd_k) √ó V

N√çVEL 4: C√ìDIGO
def attention(Q, K, V):
    ...

N√çVEL 5: EXEMPLO CONCRETO
# Input: "The cat sat"
# Query: "cat"
# Attention: [0.05, 0.30, 0.40, ...]
```

---

### 23. SFT E DPO PARA DOCUMENTA√á√ÉO

[Conte√∫do do META_GUIA sobre SFT e DPO]

#### 23.1 Supervised Fine-Tuning

**Dataset de SFT para Docs:**

```json
{
  "instruction": "Documente a fun√ß√£o calculate_loss()",
  
  "context": {
    "code": "def calculate_loss(logits, labels): ...",
    "usage": "loss = calculate_loss(output, target)"
  },
  
  "output": "# calculate_loss()\n\n**Purpose:** ..."
}
```

#### 23.2 Direct Preference Optimization

**Preference Pairs:**

```json
{
  "prompt": "Document the train() method",
  
  "chosen": "# train()\n\n**Purpose:** ...\n**Example:** ...",
  
  "rejected": "This method trains the model. Just call it."
}
```

---

### 24. FORMATOS √ìTIMOS DE DOCUMENTA√á√ÉO

[Conte√∫do do META_GUIA sobre formatos]

#### 24.1 Markdown Estruturado

```markdown
# Nome da Fun√ß√£o

> TL;DR: Uma linha de ess√™ncia

## Metadados
- Tipo: Function
- Complexidade: ‚≠ê‚≠ê‚≠ê

## Quick Start
```python
result = funcao(input)
```

## API Reference
[Detalhes completos...]
```

#### 24.2 JSON Schema

```json
{
  "function": "train",
  "signature": "train() -> TrainOutput",
  "parameters": [...],
  "returns": {...},
  "examples": [...]
}
```

---

## PARTE VI: IMPLEMENTA√á√ÉO

### 25. PLANO DE 6 DIAS

**SEGUNDA (Dia 1): Ra√≠zes & Tronco**
```bash
# Criar estrutura
mkdir -p lcm-ai/{00_‚àû_hub,skills,-01_capture,-02_build,+01_intake}

# Files b√°sicos
touch 00_‚àû_hub/{core.py,config.yaml,system_prompt.md}
```

**TER√áA (Dia 2): Primeiro Cora√ß√£o**
```python
# Implementar core.py m√≠nimo
# Integrar skill_synthesizer
# Testar: 1 doc ‚Üí Trinity
```

**QUARTA (Dia 3): Tokeniza√ß√£o**
```python
# Integrar skill_tokenizer
# Validar chunks Fibonacci
# Testar com 100 docs
```

**QUINTA (Dia 4): Taxonomia**
```python
# Integrar skill_purpose_extractor
# Refinar TF-IDF
# Ajustar vocabul√°rio
```

**SEXTA (Dia 5): Pipeline Completo**
```python
# Integrar skill_qa_generator + evaluator
# Testar 1000 docs
# Monitorar performance
```

**S√ÅBADO (Dia 6): An√°lise**
```python
# Gerar monitoring.jsonl
# Identificar gargalos
# Planejar pr√≥xima itera√ß√£o
```

---

### 26. CONFIGURA√á√ïES E TEMPLATES

#### 26.1 Config.yaml Completo

[J√° detalhado na Se√ß√£o 6.3]

#### 26.2 System Prompt Template

```markdown
# system_prompt.md

Voc√™ √© o Core Orchestrator do sistema LCM-AI.

## Seu Papel
- Coordenar Skills
- Tomar decis√µes baseadas em config.yaml
- Monitorar qualidade
- Aprender com feedback

## Seus Princ√≠pios
1. Separa√ß√£o de responsabilidades
2. Auditabilidade total
3. Aprendizado cont√≠nuo
4. Escalabilidade org√¢nica

## Processo Padr√£o
Para cada documento:
1. Receber em +01_intake/
2. Chamar Skills na ordem
3. Emitir Trinity
4. Indexar
5. Disponibilizar em +05_delivery/
6. Aguardar feedback em +08_feedback/

## Formato de Resposta
Sempre JSON estruturado para parsing determin√≠stico.
```

---

### 27. TESTES E VALIDA√á√ÉO

#### 27.1 Testes Unit√°rios (Skills)

```python
import pytest
from skills.skill_synthesizer import synthesize

def test_synthesizer_levels():
    """Testa se synthesizer gera todos n√≠veis Fibonacci"""
    text = "Long document text..." * 100
    levels = [1, 2, 3, 5, 8]
    
    summaries = synthesize(text, levels)
    
    # Assert: todos n√≠veis presentes
    assert set(summaries.keys()) == set(levels)
    
    # Assert: progress√£o de tamanho
    for i in range(len(levels) - 1):
        assert len(summaries[levels[i]]) < len(summaries[levels[i+1]])

def test_tokenizer_fibonacci():
    """Testa chunks Fibonacci"""
    from skills.skill_tokenizer import tokenize
    
    text = "word " * 10000
    sizes = [128, 256, 384]
    
    chunks = tokenize(text, sizes)
    
    # Assert: todos tamanhos presentes
    assert set(chunks.keys()) == set(sizes)
    
    # Assert: chunks menores = mais quantidade
    assert len(chunks[128]) > len(chunks[256])
```

#### 27.2 Testes de Integra√ß√£o

```python
def test_full_pipeline():
    """Testa pipeline completo: doc ‚Üí Trinity"""
    from lcm_core import LCMCore
    
    core = LCMCore()
    
    # Documento de teste
    test_doc = """
    # Test Document
    This is a test document with enough content
    to trigger all Skills in the pipeline.
    [... 500 mais palavras ...]
    """
    
    # Processar
    result = core.process_document(test_doc)
    
    # Valida√ß√µes
    assert 'trinity' in result
    assert 'quality' in result
    assert result['quality']['score'] > 0.5
    
    # Trinity completo
    trinity = result['trinity']
    assert os.path.exists(trinity['md'])
    assert os.path.exists(trinity['llm_json'])
    assert os.path.exists(trinity['meta_json'])
```

#### 27.3 Golden Tests

```python
def test_golden_output():
    """
    Testa se output permanece consistente
    (regression test)
    """
    golden_input = load_file("tests/golden/input.txt")
    golden_output = load_json("tests/golden/expected_output.json")
    
    # Processar
    actual = core.process_document(golden_input)
    
    # Comparar (permite pequenas varia√ß√µes)
    similarity = compute_similarity(actual, golden_output)
    assert similarity > 0.95
```

---

### 28. ANTIPADR√ïES E BOAS PR√ÅTICAS

#### 28.1 ‚ùå ANTIPADR√ïES

**1. Duplica√ß√£o de L√≥gica At√¥mica**
```python
# ‚ùå RUIM: Mesma l√≥gica em 3 lugares
def skill_a():
    result = extract_keywords(text)  # Duplicado

def slash_command():
    result = extract_keywords(text)  # Duplicado

def subagent():
    result = extract_keywords(text)  # Duplicado

# ‚úÖ BOM: L√≥gica em um lugar
# Slash command /extract/keywords √© primitivo
# Skill e Subagent CHAMAM o slash command
```

**2. Pr√©-carregar Contexto Gigante**
```python
# ‚ùå RUIM: Carrega tudo no in√≠cio
context = load_all_32k_files()  # 5GB na mem√≥ria

# ‚úÖ BOM: Progressive disclosure
context = load_metadata_only()  # 5MB
# Carrega conte√∫do sob demanda quando necess√°rio
```

**3. Skills Aninhados Demais**
```python
# ‚ùå RUIM: Skill ‚Üí Skill ‚Üí Skill ‚Üí Skill (4 n√≠veis)
# Fica n√£o-determin√≠stico e dif√≠cil debug

# ‚úÖ BOM: Skill ‚Üí Slash Commands (2 n√≠veis max)
# Ou Skill ‚Üí Subagent ‚Üí Slash
```

**4. Sem Auditoria**
```python
# ‚ùå RUIM: Processa sem logging
result = process_secret_sauce(doc)

# ‚úÖ BOM: Log tudo
log_entry = {
    'input_hash': sha256(doc),
    'timestamp': now(),
    'skills_used': [...]
}
monitoring_log.append(log_entry)
```

#### 28.2 ‚úÖ BOAS PR√ÅTICAS

**1. Separa√ß√£o Clara de Camadas**
```
Dados (‚àí)  ‚â†  L√≥gica (‚àû)  ‚â†  Interface (+)
```

**2. Trinity Sempre**
```
Todo artefato = .md + .llm.json + .meta.json
```

**3. Feedback Loop Implementado**
```python
# Sempre permitir feedback
user_feedback ‚Üí adjust_weights ‚Üí better_next_time
```

**4. Versionamento de Skills**
```yaml
skills:
  synthesizer:
    version: "1.2.0"
    # Mudan√ßa de vers√£o = mudan√ßa de comportamento
```

**5. Config como C√≥digo**
```yaml
# config.yaml √© versionado no Git
# Mudan√ßas s√£o rastre√°veis
# Rollback √© poss√≠vel
```

---

## PARTE VII: CASOS DE USO

### 29. E-COMMERCE E MARKETPLACE

**Cen√°rio:** Criar 100 an√∫ncios de produtos para Mercado Livre

**Workflow:**

```python
# 1. Preparar brief de cada produto
briefs = load_products_csv("products.csv")

# 2. Pipeline de agentes para cada produto
pipeline = AgentPipeline()

for product in briefs:
    # Research
    research = pipeline.agent1.research({
        'produto': product['nome'],
        'marca': product['marca'],
        'categoria': product['categoria'],
        'publico_alvo': product['publico'],
        'marketplaces': ['mercadolivre']
    })
    
    # Copy
    copy = pipeline.agent2.generate_copy(
        brief=product,
        research_notes=research
    )
    
    # Visual
    images = pipeline.agent3.generate_visuals(
        brief=product,
        research_notes=research,
        copy_pack=copy
    )
    
    # Salvar
    save_listing(product['id'], research, copy, images)
```

**Resultado:**
- 100 an√∫ncios completos
- T√≠tulos otimizados para SEO
- Descri√ß√µes persuasivas
- 9 imagens por produto (900 total)
- Tudo audit√°vel e versionado

---

### 30. DOCUMENTA√á√ÉO T√âCNICA

**Cen√°rio:** Documentar codebase de 500 arquivos Python

**Workflow:**

```python
# 1. Scan codebase
files = scan_directory("src/", pattern="*.py")

# 2. Processar cada arquivo
core = LCMCore()

for file_path in files:
    code = read_file(file_path)
    
    # Processar via LCM-AI
    result = core.process_document(code)
    
    # Trinity gerado automaticamente:
    # - file.md: Documenta√ß√£o humana
    # - file.llm.json: Para consumption de IA
    # - file.meta.json: Metadados (fun√ß√µes, classes, deps)

# 3. Gerar site de docs
generate_doc_site("‚àí02_build/")
```

**Resultado:**
- Docs atualizados automaticamente
- Busca sem√¢ntica funcional
- Q&A geradas para cada m√≥dulo
- Grafo de depend√™ncias visualizado

---

### 31. GEST√ÉO DE CONHECIMENTO

**Cen√°rio:** Organizar 32.671 arquivos desorganizados

**Before:**
```
/Desktop/
  doc1.pdf
  doc1_v2.pdf
  doc1_FINAL.pdf
  doc1_FINAL_FINAL.pdf
  [... 32.667 mais ...]
```

**After:**
```
/lcm-ai/
  ‚àí02_build/
    ai-ml/
      transformer/
        education/
          abc123.md
          abc123.llm.json
          abc123.meta.json
    business/
      strategy/
        planning/
          [...]
  views/
    by-domain/
      ai-ml ‚Üí symlinks
    by-purpose/
      education ‚Üí symlinks
```

**Processo:**
```python
# 1. Capturar tudo
for file in glob("Desktop/*"):
    copy_to("‚àí01_capture/")

# 2. Processar em lote
core = LCMCore()

for captured_file in list_captured():
    core.process_document(captured_file)

# 3. Sistema organiza automaticamente
# 4. Duplicatas eliminadas via SHA256
# 5. Busca funciona
```

**Resultado:**
- 32.671 ‚Üí ~8.000 artefatos √∫nicos
- Duplicatas removidas
- Busca em 0.2s
- Organiza√ß√£o sem√¢ntica autom√°tica

---

## AP√äNDICES

### AP√äNDICE A: GLOSS√ÅRIO COMPLETO

**Agente:** Sistema especializado que executa workflow espec√≠fico

**Artefato:** Output processado (Trinity: .md + .llm.json + .meta.json)

**Core-4:** Contexto, Modelos, Prompt, Ferramentas (pilares Claude Code)

**DPO:** Direct Preference Optimization (alinhamento sem reward model)

**Galhos (+):** Camada de distribui√ß√£o/output

**Hub (‚àû):** Orquestrador central (tronco da √°rvore)

**LCM-AI:** Living Contextual Memory for AI (sistema de gest√£o de conhecimento)

**MCP:** Model Context Protocol (integra√ß√µes externas)

**Ra√≠zes (‚àí):** Camada de ingest√£o/arquivo

**SFT:** Supervised Fine-Tuning (treinamento em exemplos rotulados)

**Skill:** Orquestra√ß√£o aut√¥noma de m√∫ltiplas a√ß√µes

**Slash Command:** Primitivo at√¥mico determin√≠stico

**Subagent:** Especialista com contexto isolado

**Trinity:** Trio de arquivos (.md, .llm.json, .meta.json)

**TUO:** Taxonomy Universal Ontology (domain/entity/purpose)

---

### AP√äNDICE B: REFER√äNCIAS E BIBLIOGRAFIA

**Papers:**
1. "Attention Is All You Need" (Vaswani et al., 2017)
2. "SmolLM2: When Smol Goes Big" (HuggingFace, 2025)
3. "Direct Preference Optimization" (Rafailov et al., 2024)

**Reposit√≥rios:**
1. HuggingFace Transformers: https://github.com/huggingface/transformers
2. TRL (Transformer Reinforcement Learning): https://github.com/huggingface/trl
3. Claude Code: https://docs.claude.com/code

**Documenta√ß√£o:**
1. SmolLM Training Playbook: https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook
2. Model Context Protocol: https://modelcontextprotocol.io
3. Anthropic API Docs: https://docs.claude.com

---

### AP√äNDICE C: CHEAT SHEETS

#### C.1 Quick Reference: Hierarquia

```
Slash Command (primitivo at√¥mico)
    ‚Üì usa
Subagent (especialista isolado) ‚Üê‚Üí MCP (integra√ß√£o externa)
    ‚Üì orquestra
Skill (workflow aut√¥nomo)
    ‚Üì empacota
Plugin (bundle compartilh√°vel)
```

#### C.2 Quick Reference: Estrutura LCM-AI

```
RA√çZES (‚àí):  ‚àí01 ‚Üí ‚àí02 ‚Üí ‚àí03 ‚Üí ‚àí05 ‚Üí ‚àí08
TRONCO (‚àû):  00_hub (core.py + config.yaml)
GALHOS (+):  +01 ‚Üí +02 ‚Üí +03 ‚Üí +05 ‚Üí +08
FOLHAS (8):  Skills (5 transforma√ß√µes)
FRUTO (13):  Apps (APIs, Web, Mobile)
```

#### C.3 Quick Reference: Plano 6 Dias

```
D1: Estrutura base
D2: Core + synthesizer
D3: Tokenizer + 100 docs
D4: Purpose extractor
D5: Pipeline completo
D6: An√°lise + itera√ß√£o
```

---

## üéØ CONCLUS√ÉO

Voc√™ agora possui:

‚úÖ **Arquitetura completa** (LCM-AI: Ra√≠zes ‚Üí Tronco ‚Üí Galhos ‚Üí Folhas ‚Üí Fruto)  
‚úÖ **Workflows de Agentes** (Research ‚Üí Copy ‚Üí Visual)  
‚úÖ **Hierarquia Claude Code** (Slash ‚Üí Subagent ‚Üí MCP ‚Üí Skill ‚Üí Plugin)  
‚úÖ **Meta-conhecimento** (Como LLMs aprendem, SFT, DPO, Destila√ß√£o)  
‚úÖ **Plano de implementa√ß√£o** (6 dias para MVP)  
‚úÖ **Boas pr√°ticas** (Antipadr√µes, testes, valida√ß√£o)

**Este sistema √©:**
- üå± **Vivo**: Respira, cresce, aprende com feedback
- üå≥ **Estruturado**: Cada camada tem responsabilidade clara
- üîÑ **C√≠clico**: Fruto ‚Üí Semente ‚Üí Nova √°rvore
- üìà **Escal√°vel**: Come√ßa simples, evolui naturalmente

**Pr√≥ximo passo:** Escolha um caso de uso e implemente o MVP em 6 dias.

---

*Sistema constru√≠do com met√°foras, executado com c√≥digo, aprendendo dia a dia.*

**LCM-AI ¬∑ Agentes ¬∑ Claude Code ¬∑ Meta-Conhecimento**  
**Vers√£o 2.0 ¬∑ 2025**
