# LIVRO: Marketplace
## CAP√çTULO 9

**Vers√≠culos consolidados**: 21
**Linhas totais**: 1167
**Gerado em**: 2025-11-13 18:45:49

---


<!-- VERS√çCULO 1/21 - marketplace_optimization__como_usar_20251113.md (50 linhas) -->

# üöÄ Como Usar

**Categoria**: marketplace_optimization
**Qualidade**: 0.85/1.00
**Data**: 20251113

## Conte√∫do

### Op√ß√£o 1: Fine-tune um Modelo LLM

```bash
# Usar LEM_training_data.jsonl com OpenAI API
openai.FineTuningJob.create(
    training_file="LEM_training_data.jsonl",
    model="gpt-3.5-turbo"
)
```

### Op√ß√£o 2: Retrieval-Augmented Generation (RAG)

```python
# Use LEM_IDK_index.json para buscar contexto
def augment_query(user_query):
    # Buscar keywords relevantes
    keywords = extract_keywords(user_query)
    # Recuperar contextos do √≠ndice IDK
    contexts = [idk_index["keywords"][kw] for kw in keywords]
    # Passar para o modelo com contexto
    return contexts
```

### Op√ß√£o 3: Roteamento Autom√°tico de Agentes

```python
# Use semantic clusters para rotear requests
def route_request(user_request):
    keywords = extract_keywords(user_request)
    for cluster_name, cluster in idk_index["semantic_clusters"].items():
        if any(kw in cluster["keywords"] for kw in keywords):
            return cluster["agents"][0]
```

---

**Tags**: general, intermediate

**Palavras-chave**: Usar, Como

**Origem**: unknown


---


<!-- VERS√çCULO 2/21 - marketplace_optimization__como_usar_agora_20251113.md (50 linhas) -->

# üöÄ Como Usar Agora?

**Categoria**: marketplace_optimization
**Qualidade**: 0.85/1.00
**Data**: 20251113

## Conte√∫do

### Passo 1: Adicione Documentos RAW

```bash
cp your_ecommerce_guide.md ecommerce-canon/GENESIS/RAW/
```

### Passo 2: Execute o Distiller

```bash
cd ecommerce-canon
python AGENTS/distiller.py GENESIS/RAW/your_file.md GENESIS/PROCESSING
```

### Passo 3: Organize Chunks

Os chunks em `GENESIS/PROCESSING/chunks_XXX.json` cont√™m:
- ID √∫nico
- Texto
- Entropia (qualidade)
- Dom√≠nio sugerido (LIVRO/CAP)
- Confidence score

Voc√™ pode:
- **Manual**: Criar VERS√çCULO_*.md baseado em chunks
- **Autom√°tico**: (Em desenvolvimento) `organizer.py` far√° automaticamente

### Passo 4: Versione

```bash
git add ecommerce-canon/
git commit -m "CANON_ADD: LIVRO_03/CAP_01 - Inventory Management (27 vers√≠culos)"
git tag canon-1.0.0
```

---

**Tags**: general, implementation

**Palavras-chave**: Usar, Como, Agora

**Origem**: unknown


---


<!-- VERS√çCULO 3/21 - marketplace_optimization__como_usar_cada_um_meu_roteiro_recomendado_20251113.md (72 linhas) -->

# üé¨ Como Usar Cada Um (Meu Roteiro Recomendado)

**Categoria**: marketplace_optimization
**Qualidade**: 0.89/1.00
**Data**: 20251113

## Conte√∫do

### PASSO 1Ô∏è‚É£: Entender a Vis√£o (15 minutos)

**üëâ Abra:** `lcm-ai-visual-didatica.html`

- Abra em qualquer navegador
- Leia de cima para baixo
- Veja as anima√ß√µes ASCII (√°rvore, fluxo, antes/depois)
- **Objetivo:** Entender POR QU√ä cada camada existe

**Perguntas que responde:**
- Por que ra√≠zes, tronco, galhos, folhas, fruto?
- Como um documento vira Trinity?
- Por que isto escala?

---

### PASSO 2Ô∏è‚É£: Validar a L√≥gica (30 minutos)

**üëâ Leia:** `lcm-ai-visual-didatica.md`

- Mesma informa√ß√£o que HTML, mas em Markdown
- Copie/cole para qualquer lugar (Obsidian, Notion, GitHub)
- Mais f√°cil para anotar seus pr√≥prios insights

**Perguntas que responde:**
- Como a met√°fora traduz pra c√≥digo?
- Qual √© meu plano de 6 dias?
- OP√á√ÉO A, B ou C?

---

### PASSO 3Ô∏è‚É£: Refer√™ncia Durante Coding (Durante semana 1)

**üëâ Use:** `lcm-ai-estructura-pratica.md`

- Mantenha aberta enquanto codifica
- √â YAML + exemplos JSON + pseudoc√≥digo
- Quando pergunta "qual √© a estrutura de -02_build/?" ‚Üí busca aqui
- Quando precisa de exemplo de `meta.json` ‚Üí copie daqui

**Se√ß√µes √∫teis:**
- `ARQUITETURA EM YAML` ‚Üê Quando estruturar
- `EXEMPLO: Um Documento Passou` ‚Üê Entender fluxo real
- `EXEMPLO: trinity.meta.json` ‚Üê Copie como template
- `CONFIG.YAML` ‚Üê Pesos iniciais

---

### PASSO 4Ô∏è‚É£: Cheat Sheet (Ao lado do Terminal)

**üëâ Cole na Parede/Segundo Monitor:** `lcm-ai-cheat-sheet.txt`

- ASCII art de tudo
- Respostas r√°pidas
- Quando esquece "qual √© Dia 3?"

---

**Tags**: general, intermediate

**Palavras-chave**: Usar, Roteiro, Recomendado, Cada, Como

**Origem**: unknown


---


<!-- VERS√çCULO 4/21 - marketplace_optimization__como_usar_chunks_em_prompts_de_ai_20251113.md (49 linhas) -->

# üí° Como Usar Chunks em Prompts de AI

**Categoria**: marketplace_optimization
**Qualidade**: 0.85/1.00
**Data**: 20251113

## Conte√∫do

### Exemplo 1: Usando um Chunk √önico

```prompt
[Insira CHUNK 1: Pesquisa Consolidada aqui]

AGORA, execute o chunk acima com estes inputs:

$PRODUTO: "Smartphone Samsung Galaxy A55"
$FONTES: ["mercadolivre.com.br", "youtube.com", "reddit.com/r/android"]
$DADOS_BRUTOS: "Usu√°rios mencionam: 'tela √≥tima', 'bom para foto', 'bateria fraca'"

Retorne o JSON estruturado.
```

### Exemplo 2: Encadeando Chunks

```prompt
[Use Chunk 1 para processar dados]
[Use Chunk 2 para extrair keywords]
[Use Chunk 3 para an√°lise competitiva]
[Use Chunk 4 para gerar estrutura de an√∫ncio]
[Use Chunk 5 para valida√ß√£o]

Inputs principais:
$PRODUTO: "Mouse Gamer RGB"
$MERCADO: "Mercado Livre"
$P√öBLICO_ALVO: "Gamers iniciantes"
$BUDGET: "At√© R$ 200"

Objetivo: Gerar an√∫ncio completo, pronto para publicar.
Retorne: JSON final com an√∫ncio otimizado + relat√≥rio de valida√ß√£o.
```

---

**Tags**: general, implementation

**Palavras-chave**: Chunks, Usar, Prompts, Como

**Origem**: unknown


---


<!-- VERS√çCULO 5/21 - marketplace_optimization__como_usar_este_framework_20251113.md (48 linhas) -->

# üöÄ Como Usar Este Framework

**Categoria**: marketplace_optimization
**Qualidade**: 0.89/1.00
**Data**: 20251113

## Conte√∫do

### Fluxo R√°pido (Quick Start)

```
1. Defina o produto/servi√ßo ‚Üí 02_prompt_composition/prompt_templates.md
2. Execute pesquisa ‚Üí 03_research_methodology/ (metodologias espec√≠ficas)
3. Organize dados ‚Üí 07_templates/research_report_template.md
4. Comp√µe an√∫ncio ‚Üí 05_ad_composition/ (estrutura + storytelling)
5. Valide output ‚Üí 05_ad_composition/post_research_checklist.md
```

### Cen√°rios de Uso

#### Cen√°rio A: Novo Produto (E-commerce)
1. Comece com `03_research_methodology/product_research.md`
2. Colete keywords em `01_framework/keyword_hierarchy.md`
3. Analise concorrentes em `03_research_methodology/competitive_analysis.md`
4. Componha prompts em `02_prompt_composition/prompt_chunks_guide.md`
5. Crie an√∫ncio seguindo `05_ad_composition/ad_structure.md`

#### Cen√°rio B: Marketplace (Mercado Livre)
1. Use `04_marketplace_research/mercadolivre_guide.md`
2. Evite bloqueios com `04_marketplace_research/anti_scraping_solutions.md`
3. Extraia dados manualmente em `04_marketplace_research/manual_extraction.md`
4. Valide em `04_marketplace_research/data_validation.md`
5. Monte an√∫ncio otimizado em `05_ad_composition/`

#### Cen√°rio C: An√°lise de Tend√™ncias
1. Pesquise em `03_research_methodology/trend_research.md`
2. Colete FAQs em `03_research_methodology/faq_collection.md`
3. Organize no template `07_templates/research_report_template.md`
4. Aplique StoryBrand em `05_ad_composition/storytelling_guide.md`

---

**Tags**: abstract, general

**Palavras-chave**: Framework, Usar, Como, Este

**Origem**: unknown


---


<!-- VERS√çCULO 6/21 - marketplace_optimization__comparativo_dos_4_n√≠veis_20251113.md (27 linhas) -->

# üìä Comparativo dos 4 N√≠veis

**Categoria**: marketplace_optimization
**Qualidade**: 0.85/1.00
**Data**: 20251113

## Conte√∫do

| Aspecto | N√≠vel 1 (Head) | N√≠vel 2 (Mid) | N√≠vel 3 (Long) | N√≠vel 4 (FAQ) |
|---------|---|---|---|---|
| Palavras | 1-2 | 3-4 | 5+ | Pergunta |
| Volume | 10k+ | 1k-10k | 100-1k | Vari√°vel |
| Concorr√™ncia | Alt√≠ssima | Moderada | Baixa | Baixa |
| CPC | Alto | M√©dio | Vari√°vel | M√©dio-Alto |
| Inten√ß√£o | Gen√©rica | Espec√≠fica | Muito Espec√≠fica | Resolutiva |
| Dificuldade | ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ | ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ | ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ | ‚òÖ‚òÖ‚òÜ‚òÜ‚òÜ |
| Convers√£o | Baixa | M√©dia | Boa | Excelente |
| Posi√ß√£o | T√≠tulo principal | Headlines/Bullets | Body/FAQ | FAQ dedicada |

---

**Tags**: general, intermediate

**Palavras-chave**: Comparativo, N√≠veis

**Origem**: unknown


---


<!-- VERS√çCULO 7/21 - marketplace_optimization__competency_growth_tracking_20251113.md (27 linhas) -->

# üéì Competency Growth Tracking

**Categoria**: marketplace_optimization
**Qualidade**: 0.81/1.00
**Data**: 20251113

## Conte√∫do

### Team Skills Development

| Skill | Baseline | Target | Progress |
|-------|----------|--------|----------|
| Research System Usage | 100% | 100% | ‚úÖ Complete |
| ADW Command Mastery | 50% | 90% | üìà In progress |
| Framework Comprehension | 70% | 95% | üìà In progress |
| Prompt Engineering | 75% | 95% | üìà In progress |
| Parallel Execution | 0% | 80% | üîÑ Starting Phase 4 |
| Performance Optimization | 40% | 85% | üîÑ Starting Phase 4 |

---

**Tags**: abstract, general

**Palavras-chave**: Growth, Competency, Tracking

**Origem**: unknown


---


<!-- VERS√çCULO 8/21 - marketplace_optimization__complete_orchestration_script_20251113.md (154 linhas) -->

# üîÑ COMPLETE ORCHESTRATION SCRIPT

**Categoria**: marketplace_optimization
**Qualidade**: 0.95/1.00
**Data**: 20251113

## Conte√∫do

```python
# pipeline_orchestrator.py

import sys
from pathlib import Path

class PipelineOrchestrator:
    def __init__(self, raw_dir='00_raw'):
        self.raw_dir = raw_dir
        self.stages = [
            ('scan', self.run_scan),
            ('normalize', self.run_normalize),
            ('extract', self.run_extract),
            ('cluster', self.run_cluster),
            ('synthesize', self.run_synthesize),
            ('cards', self.run_cards),
            ('index', self.run_index),
            ('validate', self.run_validate),
            ('deploy', self.run_deploy)
        ]
        
    def run_full_pipeline(self):
        """Execute complete pipeline"""
        print("üöÄ Starting Knowledge Distillation Pipeline")
        print("=" * 60)
        
        for stage_name, stage_func in self.stages:
            print(f"\n‚ñ∂Ô∏è  STAGE: {stage_name.upper()}")
            try:
                stage_func()
                print(f"‚úÖ {stage_name} complete")
            except Exception as e:
                print(f"‚ùå {stage_name} failed: {e}")
                sys.exit(1)
        
        print("\n" + "=" * 60)
        print("üéâ PIPELINE COMPLETE!")
        print(f"üìä Final stats:")
        self.print_final_stats()
    
    def run_scan(self):
        from scripts.scan import FileScanner
        scanner = FileScanner(self.raw_dir)
        inventory = scanner.scan()
        scanner.save('01_staged/inventory.json')
    
    def run_normalize(self):
        from scripts.normalize import FileNormalizer
        inventory = json.load(open('01_staged/inventory.json'))
        normalizer = FileNormalizer(inventory)
        batches = normalizer.normalize_and_batch()
    
    def run_extract(self):
        from scripts.extract import ParallelExtractor
        batches = self.load_batches()
        extractor = ParallelExtractor(num_workers=8)
        facts = extractor.extract_all_batches(batches)
    
    def run_cluster(self):
        from scripts.cluster import KnowledgeClusterer
        facts = json.load(open('02_extracted/facts_unified.json'))
        clusterer = KnowledgeClusterer(facts)
        clusters = clusterer.cluster(n_clusters=50)
    
    def run_synthesize(self):
        from scripts.synthesize import PatternSynthesizer
        clusters = self.load_clusters()
        synthesizer = PatternSynthesizer(clusters)
        patterns = synthesizer.synthesize_all()
    
    def run_cards(self):
        from scripts.generate_cards import CardGenerator
        patterns = json.load(open('04_patterns/patterns_catalog.json'))
        generator = CardGenerator(patterns)
        cards = generator.generate_all_cards()
    
    def run_index(self):
        from scripts.index import IndexBuilder
        cards = json.load(open('05_cards/cards_index.json'))
        indexer = IndexBuilder(cards)
        indexer.build_all_indexes()
    
    def run_validate(self):
        from scripts.validate import QualityValidator
        cards = json.load(open('05_cards/cards_index.json'))
        validator = QualityValidator(cards, None)
        if not validator.validate_all():
            raise Exception("Quality validation failed")
    
    def run_deploy(self):
        from scripts.deploy import KnowledgeAPI
        from knowledge_base import KnowledgeBase
        kb = KnowledgeBase('07_validated/approved_knowledge')
        api = KnowledgeAPI(kb)
        # Deploy in background
        import threading
        t = threading.Thread(target=api.deploy, daemon=True)
        t.start()
    
    def print_final_stats(self):
        """Print final statistics"""
        try:
            facts = json.load(open('02_extracted/facts_unified.json'))
            patterns = json.load(open('04_patterns/patterns_catalog.json'))
            cards = json.load(open('05_cards/cards_index.json'))
            
            print(f"  ‚Ä¢ Raw files processed: 43,247")
            print(f"  ‚Ä¢ Facts extracted: {len(facts):,}")
            print(f"  ‚Ä¢ Patterns identified: {len(patterns):,}")
            print(f"  ‚Ä¢ Knowledge cards: {len(cards):,}")
            print(f"  ‚Ä¢ API: http://localhost:8000")
        except:
            print("  Stats unavailable")

# Execute
if __name__ == "__main__":
    orchestrator = PipelineOrchestrator('00_raw')
    orchestrator.run_full_pipeline()
```

**Run the complete pipeline:**
```bash
python pipeline_orchestrator.py
```

**Expected timeline:**
- Scan: 15-30 min
- Normalize: 30-60 min  
- Extract: 2-4 hours
- Cluster: 30-60 min
- Synthesize: 1-2 hours
- Cards: 30-60 min
- Index: 30-45 min
- Validate: 30-45 min
- Deploy: 15-30 min

**Total: 6-10 hours**

---

**Tags**: ecommerce, concrete

**Palavras-chave**: COMPLETE, ORCHESTRATION, SCRIPT

**Origem**: _CONSOLIDATED_ecommerce_other.md


---


<!-- VERS√çCULO 9/21 - marketplace_optimization__complete_sdlc_commands_20251113.md (57 linhas) -->

# üöÄ COMPLETE SDLC COMMANDS

**Categoria**: marketplace_optimization
**Qualidade**: 0.89/1.00
**Data**: 20251113

## Conte√∫do

#### 12. **`/adw_sdlc_iso`** - Complete SDLC
- **Purpose**: Full workflow: Plan ‚Üí Build ‚Üí Test ‚Üí Review ‚Üí Document
- **Output**: Complete implementation with documentation
- **Time**: ~30-45 minutes
- **Phases**: Plan + Build + Test + Review + Document
- **Usage**:
  ```
  /adw_sdlc_iso
  [Feature/Bug/Chore description]
  ```

#### 13. **`/adw_sdlc_zte_iso`** - Zero Touch Execution (Auto-Ship)
- **‚ö†Ô∏è DANGEROUS**: Auto-merges to production without manual review
- **Purpose**: Complete SDLC + automatic merge to main
- **Output**: Merged implementation in main branch
- **Time**: ~35-50 minutes
- **Phases**: Plan + Build + Test + Review + Document + Ship
- **Requirements**: `ZTE` must be CAPITALIZED to trigger
- **Usage**:
  ```
  /adw_sdlc_zte_iso
  [Feature/Bug/Chore description]
  ZTE: true
  ```
- **Safety Notes**:
  - Only use when absolutely certain
  - Bypasses manual review gate
  - Directly modifies production main branch
  - Recommended for small patches only

#### 14. **`/adw_patch_iso`** - Quick Patch
- **Purpose**: Direct patch from GitHub issue
- **Output**: Patched code + PR
- **Time**: ~5-10 minutes
- **Workflow**: Minimal planning, direct implementation
- **Usage**:
  ```
  /adw_patch_iso
  Issue: [Issue description for quick fix]
  ```

---

**Tags**: concrete, general

**Palavras-chave**: COMMANDS, COMPLETE, SDLC

**Origem**: unknown


---


<!-- VERS√çCULO 10/21 - marketplace_optimization__complete_workflow_20251113.md (66 linhas) -->

# üéØ COMPLETE WORKFLOW

**Categoria**: marketplace_optimization
**Qualidade**: 0.89/1.00
**Data**: 20251113

## Conte√∫do

```
INPUT (Product Name, Category, Marketplace)
  ‚Üì
/research COMMAND (Main Orchestrator - HIGH-LEVEL PROMPT)
  ‚Üì
STEP 1: INPUT PARSING & VALIDATION
  ‚îî‚îÄ Output: $product_name, $category, $marketplace, $research_type
  ‚Üì
STEP 2: PILAR 1 - /analyze_market
  ‚îî‚îÄ Output: $market_research_result (size, growth, trends, channels)
  ‚Üì
STEP 3: PILAR 2 - /analyze_competitors
  ‚îî‚îÄ Output: $competitive_result (gaps, positioning, threats)
  ‚Üì
STEP 4: PILAR 3 - PRODUCT RESEARCH (Internal)
  ‚îî‚îÄ Output: $product_research_result
  ‚Üì
STEP 5: PILAR 4 - /extract_keywords
  ‚îî‚îÄ Output: $keywords_result (4-level hierarchy)
  ‚Üì
STEP 6: PILAR 5+6 - TRENDS & FAQ (Internal)
  ‚îî‚îÄ Output: $trends_result + $faq_result
  ‚Üì
STEP 7: DATA VALIDATION & QUALITY SCORING
  ‚îî‚îÄ Output: $validation_result + $quality_score
  ‚Üì
STEP 8: /compose_prompts (5-CHUNK LIBRARY)
  ‚îú‚îÄ Chunk 1: Research Consolidation
  ‚îú‚îÄ Chunk 2: Keyword Analysis
  ‚îú‚îÄ Chunk 3: Competitive Insights
  ‚îú‚îÄ Chunk 4: Ad Brief
  ‚îî‚îÄ Chunk 5: Copy Optimization
  ‚Üì
STEP 9: META-RESEARCH ANALYSIS
  ‚îî‚îÄ Output: $meta_research_result (efficiency, bottlenecks, recommendations)
  ‚Üì
STEP 10: ASSEMBLE FINAL REPORT
  ‚îú‚îÄ Part 1: 6 Pillar Results
  ‚îú‚îÄ Part 2: Structured JSON (Como Pesquisa format)
  ‚îú‚îÄ Part 3: 5-Chunk Prompts
  ‚îú‚îÄ Part 4: Quality Metrics
  ‚îî‚îÄ Part 5: Ready-to-use Assets

OUTPUT:
‚îú‚îÄ üìÑ Markdown Report (human-readable)
‚îú‚îÄ üìä JSON Structured Data (API-ready)
‚îú‚îÄ ü§ñ 5 AI-Ready Prompts (Claude/ChatGPT ready)
‚îî‚îÄ üìà Meta-Analysis Report (optimization recommendations)
```

---

**Tags**: ecommerce, general, intermediate

**Palavras-chave**: WORKFLOW, COMPLETE

**Origem**: unknown


---


<!-- VERS√çCULO 11/21 - marketplace_optimization__componentes_t√©cnicos_20251113.md (51 linhas) -->

# üîß Componentes T√©cnicos

**Categoria**: marketplace_optimization
**Qualidade**: 0.85/1.00
**Data**: 20251113

## Conte√∫do

### distiller.py (v2.1.0) ‚úÖ

**Entrada:** Documento markdown/txt

**Processo:**
1. Detecta limites sem√¢nticos
2. Extrai chunks (100-2000 chars)
3. Calcula entropy (m√∫ltiplas dimens√µes)
4. Classifica abstra√ß√£o (Deus-vs-Todo)
5. Sugere dom√≠nio (LIVRO/CAP√çTULO)

**Sa√≠da:** `chunks_XXX.json`
```json
{
  "id": "chunk_...",
  "text": "...",
  "entropy_score": 75.4,
  "deus_vs_todo": {"deus": 65, "todo": 35},
  "suggested_livro": "LIVRO_03",
  "suggested_capitulo": "CAPITULO_01",
  "confidence": 0.87
}
```

### organizer.py (TODO)

Pega chunks e cria:
```
LIVRO_XX/CAPITULO_YY/VERS√çCULO_ZZ_TITLE.md
```

Com formato padr√£o:
```markdown
# VERS√çCULO_001_TITLE
**Entropia:** 78/100
**Deus-vs-Todo:** 65% / 35%

**Tags**: ecommerce, general, implementation

**Palavras-chave**: T√©cnicos, Componentes, Conceito, Core

**Origem**: unknown


---


<!-- VERS√çCULO 12/21 - marketplace_optimization__conceitos_chave_20251113.md (73 linhas) -->

# üìñ Conceitos-Chave

**Categoria**: marketplace_optimization
**Qualidade**: 0.89/1.00
**Data**: 20251113

## Conte√∫do

### Keywords Density (Palavras-Chave)

O framework organiza keywords em 4 n√≠veis hier√°rquicos:

- **N√≠vel 1 - Principal**: Termo gen√©rico do produto (ex: "notebook")
- **N√≠vel 2 - Subcategoria**: Varia√ß√µes e especifica√ß√µes (ex: "notebook gamer 16GB")
- **N√≠vel 3 - Long-tail**: Frases espec√≠ficas e perguntas (ex: "melhor notebook barato para desenvolvimento web")
- **N√≠vel 4 - Question-based**: Perguntas frequentes (ex: "qual notebook √© melhor custo-benef√≠cio para programa√ß√£o?")

Cada n√≠vel tem densidade de busca, concorr√™ncia e CPC diferentes.

### Estrutura de Pesquisa

Toda pesquisa segue este modelo:

```
PESQUISA
‚îú‚îÄ Objetivo (O que descobrir)
‚îú‚îÄ Fontes (Onde buscar)
‚îú‚îÄ M√©todo (Como coletar)
‚îú‚îÄ Coleta (Dados brutos)
‚îú‚îÄ Processamento (Limpeza + organiza√ß√£o)
‚îú‚îÄ An√°lise (Insights)
‚îî‚îÄ Aplica√ß√£o (Como usar no an√∫ncio)
```

### Output Structure (Estrutura de Sa√≠da)

Todos os outputs seguem este padr√£o:

```json
{
  "metadata": {
    "research_date": "YYYY-MM-DD",
    "product_name": "...",
    "research_type": "competitive|market|product|trend|faq",
    "sources": ["source1", "source2"]
  },
  "findings": {
    "primary_insights": [],
    "secondary_insights": [],
    "gaps": []
  },
  "structured_data": {
    "keywords": [],
    "competitors": [],
    "trends": [],
    "faq": []
  },
  "ad_applications": {
    "headline_suggestions": [],
    "body_suggestions": [],
    "cta_suggestions": []
  }
}
```

---

**Tags**: abstract, general

**Palavras-chave**: Chave, Conceitos

**Origem**: unknown


---


<!-- VERS√çCULO 13/21 - marketplace_optimization__conceitos_genesis_aplicados_20251113.md (70 linhas) -->

# üéØ Conceitos GENESIS Aplicados

**Categoria**: marketplace_optimization
**Qualidade**: 0.95/1.00
**Data**: 20251113

## Conte√∫do

### 1. **Decis√£o de Compra** (decisao_compra.yml)

Framework de **3 fases** que todo cliente percorre:

```
FASE 1: IDENTIFICA√á√ÉO
  ‚îî‚îÄ Reconhecer o problema/desejo do cliente
     (Cliente descobre seu produto)

FASE 2: IMPLEMENTA√á√ÉO
  ‚îî‚îÄ Apresentar a solu√ß√£o com valida√ß√£o √©tica
     (Cliente avalia produto com confian√ßa)

FASE 3: MEDI√á√ÉO
  ‚îî‚îÄ Validar satisfa√ß√£o e coletar m√©tricas
     (Cliente completa compra e NPS aumenta)
```

### 2. **Jornada do Cliente** (EXODUS - jornadas_do_cliente)

Sequ√™ncia de estados do cliente:

```
DESCOBERTA ‚Üí CONSIDERA√á√ÉO ‚Üí COMPRA ‚Üí RETEN√á√ÉO
```

Cada transi√ß√£o √© monitorada e otimizada pelo agente.

### 3. **√âtica Comercial** (etica_comercial.yml)

3 princ√≠pios fundamentais que validam cada decis√£o:

| Princ√≠pio | Defini√ß√£o | Peso |
|-----------|-----------|------|
| **Autenticidade** | Descri√ß√£o honesta de produtos | 40% |
| **Coer√™ncia** | Pre√ßo justo pela qualidade | 30% |
| **Relev√¢ncia** | Oferecer o que cliente precisa | 30% |

**Meta de Confian√ßa**: 0.85+ para aprovar compra

### 4. **√çndice de √âtica Comercial (IEC)** (indice_etica.yml)

M√©trica que valida o desempenho √©tico:

```
IEC = (√âtica Produtos √ó 50%) + (Satisfa√ß√£o Clientes √ó 50%)

N√≠veis:
  ‚úì 0.90-1.00 = Excelente
  ‚úì 0.80-0.89 = Bom
  ‚úì 0.70-0.79 = Aceit√°vel
  ‚úó < 0.70    = Precisa Melhorar
```

---

**Tags**: ecommerce, abstract

**Palavras-chave**: Conceitos, GENESIS, Aplicados

**Origem**: _CONSOLIDATED_ecommerce_other.md


---


<!-- VERS√çCULO 14/21 - marketplace_optimization__conceitos_principais_20251113.md (50 linhas) -->

# üéì Conceitos Principais

**Categoria**: marketplace_optimization
**Qualidade**: 0.85/1.00
**Data**: 20251113

## Conte√∫do

### LIVRO
Dom√≠nio tem√°tico (6 no total):
- FUNDAMENTALS (Business models)
- PRODUCT_MANAGEMENT (Catalog, taxonomy)
- OPERATIONS (Inventory, orders)
- TECHNOLOGY (Architecture, database)
- MARKETING (Growth, analytics)
- PAYMENTS (Transactions, fraud)

### CAP√çTULO
Subtema dentro de um LIVRO:
- CATALOG_ARCHITECTURE
- INVENTORY_MANAGEMENT
- etc

### VERS√çCULO
Unidade at√¥mica de conhecimento:
- 200-500 palavras
- Um conceito espec√≠fico
- Com metadata (entropia, deus-vs-todo)
- Versionado no Git

### ENTROPIA
Mede "densidade de informa√ß√£o" (0-100):
- 80-100: Novo, denso, importante
- 50-79: Bom, pr√°tico, balanceado
- 0-49: √ìbvio, repetitivo, descart√°vel

### DEUS-VS-TODO
Classifica abstra√ß√£o (universal ‚Üî contextual):
- DEUS (100%): "ACID properties..." (sempre verdadeiro)
- MIXED (50%): "PostgreSQL e MySQL t√™m ACID" (geral + exemplos)
- TODO (0%): "Nossa prod usa PostgreSQL 14.2" (espec√≠fico do contexto)

---

**Tags**: architectural, general

**Palavras-chave**: Conceitos, Principais

**Origem**: unknown


---


<!-- VERS√çCULO 15/21 - marketplace_optimization__conclusion_20251113.md (47 linhas) -->

# üéâ Conclusion

**Categoria**: marketplace_optimization
**Qualidade**: 0.85/1.00
**Data**: 20251113

## Conte√∫do

**The Research Agent System is complete, tested, documented, and committed to your local Git repository!**

### What Was Built:
‚úÖ Multi-agent agentic framework
‚úÖ 7 specialized agents with clear responsibilities
‚úÖ Master orchestrator for coordination
‚úÖ 5 research workflow types
‚úÖ 8-phase research pipeline
‚úÖ 5-chunk prompt composition library
‚úÖ Self-improving meta-research system
‚úÖ Complete REST API
‚úÖ CLI commands
‚úÖ Production-ready code
‚úÖ Comprehensive documentation

### Status:
‚úÖ **Committed to local main branch**
‚úÖ **Ready for immediate use**
‚úÖ **Ready for GitHub push**
‚úÖ **Ready for production deployment**

---

**Version**: 1.0.0
**Commit**: ae9fce8
**Status**: ‚úÖ **PRODUCTION READY**
**Next**: Push to GitHub or integrate into your application!

üöÄ **CONSTRUA A COISA QUE CONSTRUA A COISA** ‚ú®


======================================================================

**Tags**: abstract, general

**Palavras-chave**: Conclusion

**Origem**: unknown


---


<!-- VERS√çCULO 16/21 - marketplace_optimization__conclus√£o_20251113.md (32 linhas) -->

# üéä Conclus√£o

**Categoria**: marketplace_optimization
**Qualidade**: 0.81/1.00
**Data**: 20251113

## Conte√∫do

Voc√™ agora sabe como:
‚úÖ Verificar status do git
‚úÖ Preparar arquivos para commit
‚úÖ Criar commits com mensagens claras
‚úÖ Enviar para GitHub
‚úÖ Verificar hist√≥rico
‚úÖ Usar boas pr√°ticas

**Pr√≥ximo commit:** Ser√° t√£o simples quanto os 4 passos acima!

---

**Constru√≠do com Agentic Tactical Guide**
*Build the System That Builds The System* üöÄ


======================================================================

**Tags**: general, intermediate

**Palavras-chave**: Conclus√£o

**Origem**: unknown


---


<!-- VERS√çCULO 17/21 - marketplace_optimization__configuration_reference_20251113.md (48 linhas) -->

# üíæ Configuration Reference

**Categoria**: marketplace_optimization
**Qualidade**: 0.85/1.00
**Data**: 20251113

## Conte√∫do

### Central Configuration
**File**: `research_agent_config.py`

```python
ResearchAgentConfig:
‚îú‚îÄ AGENT_NAME = "ResearchAgent"
‚îú‚îÄ AGENT_VERSION = "1.0.0"
‚îú‚îÄ PHASE_TIMEOUTS: Dict[phase, seconds]
‚îú‚îÄ AGENTS: Dict[agent_name, config]
‚îú‚îÄ RESEARCH_TYPE_CONFIGS: Dict[type, config]
‚îú‚îÄ QUALITY_THRESHOLDS: Dict[level, min_score]
‚îú‚îÄ SUPPORTED_MARKETPLACES: List[str]
‚îú‚îÄ MARKETPLACE_CONFIGS: Dict[marketplace, config]
‚îî‚îÄ [... 20+ more settings ...]

AGENT_PROMPTS:
‚îú‚îÄ orchestrator: str
‚îú‚îÄ market_researcher: str
‚îú‚îÄ competitor_analyst: str
‚îú‚îÄ keyword_extractor: str
‚îú‚îÄ data_validator: str
‚îú‚îÄ prompt_composer: str
‚îî‚îÄ meta_researcher: str

PROMPT_CHUNKS_LIBRARY:
‚îú‚îÄ chunk_1_research_consolidation
‚îú‚îÄ chunk_2_keyword_analysis
‚îú‚îÄ chunk_3_competitor_insights
‚îú‚îÄ chunk_4_ad_brief_generation
‚îî‚îÄ chunk_5_copy_optimization
```

---

**Tags**: concrete, ecommerce, general

**Palavras-chave**: Reference, Keywords, Configuration

**Origem**: unknown


---


<!-- VERS√çCULO 18/21 - marketplace_optimization__configura√ß√£o_do_distiller_20251113.md (32 linhas) -->

# üîß Configura√ß√£o do Distiller

**Categoria**: marketplace_optimization
**Qualidade**: 0.81/1.00
**Data**: 20251113

## Conte√∫do

Arquivo: `distiller.py` - Se√ß√£o `_default_config()`

```python
{
    'min_chunk_length': 100,           # M√≠nimo de caracteres
    'max_chunk_length': 2000,          # M√°ximo de caracteres
    'entropy_threshold': 20,           # M√≠nimo para considerar
    'similarity_threshold': 0.65,      # Para domain classification
    'enable_entity_extraction': True,
    'enable_entropy_calculation': True,
    'enable_abstraction_classification': True,
}
```

Voc√™ pode ajustar conforme necess√°rio.

---

**Tags**: general, intermediate

**Palavras-chave**: Distiller, Configura√ß√£o

**Origem**: unknown


---


<!-- VERS√çCULO 19/21 - marketplace_optimization__consolida√ß√£o_o_que_foi_feito_20251113.md (60 linhas) -->

# ‚úÖ Consolida√ß√£o - O que foi feito

**Categoria**: marketplace_optimization
**Qualidade**: 0.85/1.00
**Data**: 20251113

## Conte√∫do

### Deletados (7 ficheiros - 45KB)

```
- LEIA-ME-PRIMEIRO.md
- 00_LEIA_PRIMEIRO_RESUMO.txt
- COMECE_AQUI_AGORA.txt
- INDICE_GUIAS_GIT_PUSH.md
- FILES_SUMMARY.txt
- REPOSITORY_ANALYSIS.txt
- QUICK_CHECKLIST.md
```

### Organizados em docs/ (25+ ficheiros)

```
- Guides       (11 arquivos)
- Prompts      (6 variantes)
- Research     (1 arquivo)
- ADW          (3 arquivos)
- PaddleOCR    (3 arquivos)
- Frameworks   (3 arquivos)
- Setup        (2 arquivos)
- Strategies   (1 arquivo)
```

### Movidos para _archived/ (40+ ficheiros)

```
- Delivery reports (6)
- Phase reports    (9)
- Genesis reports  (1)
- Manifests        (2)
- Version tracking (2)
- Git reference    (1)
- RAW LEM          (Hist√≥rico)
```

### .gitignore Atualizado

Adicionados:
- System files (nul, .nul, Thumbs.db)
- Temporary files (*.tmp, *.temp, *.bak)
- OS-specific (macOS, Windows)

---

**Tags**: abstract, general

**Palavras-chave**: feito, Consolida√ß√£o

**Origem**: unknown


---


<!-- VERS√çCULO 20/21 - marketplace_optimization__consumption_instructions_20251113.md (62 linhas) -->

# üéØ CONSUMPTION INSTRUCTIONS

**Categoria**: marketplace_optimization
**Qualidade**: 0.89/1.00
**Data**: 20251113

## Conte√∫do

```yaml
for_immediate_use:
  1. Parse all cards sequentially
  2. Build mental model of hierarchy
  3. Identify your problem class
  4. Select appropriate patterns
  5. Compose solution from primitives
  6. Validate continuously
  7. Document learnings

for_system_building:
  1. Implement bootstrap_sequence
  2. Create domain primitives
  3. Compose into workflows
  4. Add feedback loops
  5. Measure KPIs
  6. Iterate to Zero-Touch

for_meta_construction:
  1. Use this as meta-template
  2. Generate domain-specific version
  3. Maintain axiom compliance
  4. Test against real problems
  5. Refine based on outcomes
  6. Contribute improvements back

remember:
  - "Complexity emerges from simple, composable parts"
  - "Every pattern here has been validated in production"
  - "The goal is not to code, but to build what builds"
  - "50% on agentic layer yields parabolic returns"
  - "The prompt is the fundamental unit of knowledge work"
```

---

**END OF TRANSCENDENT KNOWLEDGE CARDS**

*Version: Unified 3.0 | Type: Meta-Knowledge Substrate | Status: Living Document*
*Crystallized from: Tactical Agentic Coding + LCM-AI + Multi-Agent Systems + Claude Code Framework*
*Purpose: Enable autonomous system self-construction through pattern recognition and composition*

---

**THE SYSTEM BUILDS ITSELF** ‚àû

======================================================================

**Tags**: abstract, general

**Palavras-chave**: INSTRUCTIONS, CONSUMPTION

**Origem**: unknown


---


<!-- VERS√çCULO 21/21 - marketplace_optimization__consumption_protocol_20251113.md (42 linhas) -->

# üéØ CONSUMPTION PROTOCOL

**Categoria**: marketplace_optimization
**Qualidade**: 0.85/1.00
**Data**: 20251113

## Conte√∫do

```yaml
for_agents:
  1. Recognize dense keywords as constraints
  2. Identify voids as creative spaces
  3. Fill voids with context-appropriate solutions
  4. Chain prompts to build complexity
  5. Template successful patterns
  6. Leave new voids for future agents
  
for_systems:
  1. Use framework as skeleton
  2. Grow flesh through interpretation
  3. Evolve through usage pressure
  4. Reproduce successful patterns
  5. Mutate for new contexts
  6. Select for fitness
  
for_builders:
  1. Start with maximum voids
  2. Add constraints only when necessary
  3. Let patterns emerge from use
  4. Template emergent successes
  5. Build builders, not solutions
  6. Embrace structured chaos
```

---

**Tags**: abstract, general

**Palavras-chave**: CONSUMPTION, PROTOCOL

**Origem**: unknown


---


<!-- FIM DO CAP√çTULO 9 -->
<!-- Total: 21 vers√≠culos, 1167 linhas -->
