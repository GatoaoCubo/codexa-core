# ADW Workflow: 5-Phase Agent Development from Zero to Production

**Categoria**: multiagent_workflows
**Qualidade**: 0.89/1.00
**Data**: 20251120

## Conte√∫do

### O Problema com Desenvolvimento Ad-Hoc de Agentes

**Approach comum (falha 60% das vezes)**:
"Vou criar um agente que faz X. [3 horas codando] Pronto! [deployment] [bugs em produ√ß√£o] [usu√°rios confusos] [documenta√ß√£o inexistente]"

**Resultado**: Agente funciona no happy path, quebra em edge cases, ningu√©m al√©m do criador entende como usar, manuten√ß√£o √© pesadelo.

**ADW Workflow resolve**: Processo estruturado em 5 fases que garante agentes production-ready, documentados, testados e mant√≠veis.

**Analogia**: ADW √© o "Agile/Scrum" do desenvolvimento de agentes LLM. N√£o pule etapas.

### As 5 Fases do ADW (Agent Development Workflow)

#### **FASE 1: DISCOVERY (Descoberta)** [Duration: 1-3 dias]

**Objetivo**: Entender PROFUNDAMENTE o problema antes de escrever uma linha de c√≥digo.

**Atividades obrigat√≥rias**:

1. **Problem Definition**
```
- O QUE o agente deve fazer? (tarefa espec√≠fica, n√£o vaga)
- PARA QUEM? (persona espec√≠fica de usu√°rio)
- POR QUE existente n√£o resolve? (gap analysis)
```

2. **Research Existing Solutions**
```
- H√° agentes similares no mercado? (LangChain, CrewAI examples)
- O que eles fazem BEM?
- O que eles fazem MAL? (oportunidade de diferencia√ß√£o)
```

3. **Requirements Gathering**
```
Functional Requirements:
- Input: [formato exato, valida√ß√µes]
- Processing: [etapas necess√°rias]
- Output: [formato exato, success criteria]

Non-Functional Requirements:
- Latency: [‚â§X segundos]
- Cost: [‚â§$Y por request]
- Quality: [‚â•Z% consistency]
```

4. **User Stories**
```
As a [USER_PERSONA],
I want to [TASK],
So that [BUSINESS_VALUE]

Example:
As a Brazilian e-commerce seller,
I want to generate marketplace-compliant product descriptions in <60 seconds,
So that I can publish 20+ products per day without manual copywriting
```

5. **Success Metrics Definition**
```
- Metric 1: [quantific√°vel, ex: "95% dos outputs n√£o requerem edi√ß√£o humana"]
- Metric 2: [lat√™ncia, ex: "p95 latency ‚â§10s"]
- Metric 3: [custo, ex: "‚â§$0.15 per generation"]
```

**Deliverables Fase 1**:
- `DISCOVERY_REPORT.md` (5-10 p√°ginas)
- User stories (3-7 hist√≥rias principais)
- Success metrics dashboard mockup

**Validation Gate**: Stakeholders aprovam problem definition e success metrics antes de prosseguir.

#### **FASE 2: DESIGN (Arquitetura)** [Duration: 2-5 dias]

**Objetivo**: Projetar arquitetura do agente ANTES de implementar.

**Atividades obrigat√≥rias**:

1. **Agent Architecture Diagram**
```
[User Input]
    ‚Üì
[Input Validator] ‚Üí reject if invalid
    ‚Üì
[Context Loader] ‚Üí load from iso_vectorstore
    ‚Üì
[LLM Orchestrator] ‚Üí main processing
    ‚Üì
[Output Formatter] ‚Üí structure output
    ‚Üì
[Quality Validator] ‚Üí check constraints
    ‚Üì
[User Output]
```

2. **HOPs Identification**
```
Liste TODOS os procedimentos que o agente executar√°.
Para cada um, escreva draft TAC-7:
- HOP_01: [Tarefa 1]
- HOP_02: [Tarefa 2]
- HOP_03: [Tarefa 3]
... etc
```

3. **Data Flow Specification**
```json
{
  "input_schema": {
    "field1": {"type": "string", "max_length": 100, "required": true},
    "field2": {"type": "array", "items": "string", "required": false}
  },
  "output_schema": {
    "result": {"type": "string", "format": "markdown"},
    "confidence": {"type": "float", "min": 0.0, "max": 1.0},
    "metadata": {"type": "object"}
  }
}
```

4. **Technology Stack Selection**
```
- LLM: [OPEN_VARIABLE: modelo_escolhido] (justificar por qu√™)
- Orquestra√ß√£o: [OPEN_VARIABLE: framework_escolhido] ou custom?
- Storage: iso_vectorstore (20 files) + [OPEN_VARIABLE: db_opcional]
- Monitoring: [OPEN_VARIABLE: ferramenta_observability]
```

5. **Error Handling Strategy**
```
IF input invalid ‚Üí RETURN error message (never hallucinate fix)
IF LLM timeout ‚Üí RETRY 2x with exponential backoff ‚Üí THEN fallback
IF output validation fails ‚Üí LOG + ALERT ‚Üí RETURN partial result with warning
```

6. **Cost & Latency Budget**
```
Target: ‚â§$0.15 per request, ‚â§10s p95 latency

Budget breakdown:
- Input processing: $0.01, 0.5s
- LLM call (main): $0.10, 7s
- Output formatting: $0.02, 1s
- Validation: $0.02, 1.5s
TOTAL: $0.15, 10s ‚úÖ
```

**Deliverables Fase 2**:
- `DESIGN_DOC.md` (15-25 p√°ginas com diagramas)
- HOPs drafts (TAC-7 skeleton)
- Schemas (JSON para input/output)
- Technology decision record (ADR format)

**Validation Gate**: Tech lead aprova√ß√£o arquitetura + viabilidade or√ßament√°ria.

#### **FASE 3: DEVELOP (Implementa√ß√£o)** [Duration: 1-2 semanas]

**Objetivo**: Implementar o agente seguindo rigorosamente o design.

**Atividades obrigat√≥rias**:

1. **Directory Structure Setup**
```
novo_agent/
‚îú‚îÄ‚îÄ PRIME.md (contexto do agente, 400-600 linhas)
‚îú‚îÄ‚îÄ README.md (quick start para usu√°rios)
‚îú‚îÄ‚îÄ INSTRUCTIONS.md (guia de opera√ß√£o detalhado)
‚îú‚îÄ‚îÄ iso_vectorstore/ (20 arquivos de conhecimento)
‚îÇ   ‚îú‚îÄ‚îÄ 01_QUICK_START.md
‚îÇ   ‚îú‚îÄ‚îÄ 02_PRIME.md
‚îÇ   ‚îú‚îÄ‚îÄ 09_HOP_main.md
‚îÇ   ‚îú‚îÄ‚îÄ 10_HOP_secondary.md
‚îÇ   ‚îú‚îÄ‚îÄ 11_ADW_workflow.md
‚îÇ   ‚îî‚îÄ‚îÄ ... (15 more)
‚îú‚îÄ‚îÄ workflows/ (HOPs completos TAC-7)
‚îÇ   ‚îú‚îÄ‚îÄ HOP_01_main_task.md
‚îÇ   ‚îú‚îÄ‚îÄ HOP_02_validation.md
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ prompts/ (prompts LLM)
‚îÇ   ‚îú‚îÄ‚îÄ main_orchestrator.md (400+ linhas)
‚îÇ   ‚îú‚îÄ‚îÄ validator.md (200+ linhas)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ tests/ (unit + integration tests)
    ‚îú‚îÄ‚îÄ test_input_validation.py
    ‚îú‚îÄ‚îÄ test_llm_orchestration.py
    ‚îî‚îÄ‚îÄ ...
```

2. **Implementation Order** (critical!)
```
Week 1:
- Day 1-2: Input validator + schemas
- Day 3-4: Context loader (iso_vectorstore)
- Day 5: Main LLM orchestrator (basic version)

Week 2:
- Day 1-2: Output formatter + validation
- Day 3: Error handling + retries
- Day 4-5: Polish + edge cases
```

3. **Code Quality Standards**
```python
# Example: Input validator
def validate_input(data: dict) -> tuple[bool, Optional[str]]:
    """
    Validates user input against schema.

    Args:
        data: Raw input from user

    Returns:
        (is_valid, error_message)

    Raises:
        Never raises (returns error message instead)
    """
    schema = load_schema("input_schema.json")

    try:
        validate(instance=data, schema=schema)
        return (True, None)
    except ValidationError as e:
        return (False, f"Validation failed: {e.message}")
```

4. **Prompt Engineering** (iterative)
```
V1: Basic prompt (200 tokens)
‚Üí Test 10 samples
‚Üí Identify failures
V2: Add constraints + examples (400 tokens)
‚Üí Test 20 samples
‚Üí Quality +30%
V3: Add error handling instructions (450 tokens)
‚Üí Test 30 samples
‚Üí Quality +15%
V4: Production-ready (480 tokens)
```

5. **Testing Throughout** (NOT after!)
```bash
# Run tests after EVERY feature implementation
pytest tests/ --verbose

# Maintain coverage ‚â•80%
pytest --cov=novo_agent tests/

# Integration tests with real LLM
pytest tests/integration/ --slow
```

**Deliverables Fase 3**:
- Working agent code (all components)
- 20 iso_vectorstore files populated
- HOPs TAC-7 completos (‚â•3 HOPs)
- Test suite (‚â•80% coverage)

**Validation Gate**: All tests pass + code review approved.

#### **FASE 4: VALIDATE (Valida√ß√£o & QA)** [Duration: 3-5 dias]

**Objetivo**: Garantir que agente atende requisitos de qualidade ANTES de deployment.

**Atividades obrigat√≥rias**:

1. **5-Dimension Quality Check** (inspirado no mentor_agent)
```
Dimension 1: COMPLETENESS (100% de features implementadas?)
Dimension 2: CLARITY (documenta√ß√£o leg√≠vel por novatos?)
Dimension 3: ACCURACY (outputs factuais corretos?)
Dimension 4: RELEVANCE (resolve problema real de usu√°rio?)
Dimension 5: ACTIONABILITY (usu√°rio consegue usar sem help?)

Score m√≠nimo: ‚â•0.75/1.0 em CADA dimens√£o
```

2. **Benchmark Testing**
```
Test com 50+ inputs diversos:
- 30 happy path (casos t√≠picos)
- 15 edge cases (inputs incomuns mas v√°lidos)
- 5 error cases (inputs inv√°lidos)

M√©tricas:
- Success rate: ‚â•90% (happy path) + ‚â•70% (edge cases)
- Latency p50: ‚â§7s, p95: ‚â§10s, p99: ‚â§15s
- Cost per request: ‚â§$0.15
- Quality score: ‚â•8/10 (human evaluation)
```

3. **User Acceptance Testing** (UAT)
```
Recrute 3-5 usu√°rios beta (target persona):
- D√™ acesso ao agente
- N√ÉO explique como usar (teste se README √© suficiente)
- Observe sess√µes (screen recording)
- Colete feedback estruturado

Success: ‚â•80% conseguem primeira tarefa sem ajuda
```

4. **Load Testing**
```bash
# Simule carga de 100 requests simult√¢neos
locust -f load_test.py --users 100 --spawn-rate 10

Target:
- No crashes
- Latency degradation ‚â§20% (p95)
- Error rate ‚â§5%
```

5. **Security Review**
```
Checklist:
‚òê Input sanitization (SQL injection, XSS)
‚òê API keys n√£o hardcoded (usar env vars)
‚òê Rate limiting implementado
‚òê Logs n√£o exp√µem dados sens√≠veis
‚òê GDPR compliance (se aplic√°vel)
```

**Deliverables Fase 4**:
- Quality report (5-dimension scores)
- Benchmark results (50+ tests)
- UAT feedback summary
- Load test report
- Security audit passed

**Validation Gate**: Quality score ‚â•0.85 overall + UAT success ‚â•80%.

#### **FASE 5: DOCUMENT (Documenta√ß√£o & Handoff)** [Duration: 2-3 dias]

**Objetivo**: Documentar TUDO para que outros possam usar/manter o agente.

**Atividades obrigat√≥rias**:

1. **PRIME.md (Contexto Completo)**
```markdown
# /prime-[nome_agente]

## Purpose
[1 par√°grafo: O QUE o agente faz e PARA QUEM]

## Architecture Pillars
### 4 IN-AGENT Pillars
[Contexto, Modelo, Tools, Prompts]

### 8 OUT-AGENT Pillars
[Templates, Output, Types, Docs, Tests, Architecture, Plans, ADWs]

## Specialty
[Capabilities espec√≠ficas, quando usar vs quando n√£o usar]

## Key Files
[Lista de todos os arquivos importantes + descri√ß√£o]

## Workflows
[Principais workflows/HOPs + quando usar cada um]
```

2. **README.md (Quick Start)**
```markdown
# [Nome Agent]

## What it does
[2 par√°grafos: problema que resolve + como resolve]

## Quick Start
```bash
# 3-5 comandos para come√ßar
/prime-[nome]
"[exemplo de prompt]"
```

## Key Features
- Feature 1
- Feature 2
- Feature 3

## Examples
[3 exemplos: b√°sico, intermedi√°rio, avan√ßado]

## Troubleshooting
[5 problemas comuns + solu√ß√µes]
```

3. **INSTRUCTIONS.md (Operational Guide)**
```markdown
Gerado automaticamente via doc_sync ou escrito manualmente.
Cont√©m:
- Todos os HOPs do agente (TAC-7 completo)
- Comandos dispon√≠veis
- Edge cases conhecidos
- Maintenance procedures
```

4. **Video Walkthrough** (optional mas recomendado)
```
- 5-10 min screencast
- Mostra uso b√°sico + 1 exemplo avan√ßado
- Narrado explicando decis√µes
- Hospedado no YouTube/Loom
```

5. **Handoff Checklist**
```
‚òê PRIME.md completo (400+ linhas)
‚òê README.md com quick start
‚òê INSTRUCTIONS.md operacional
‚òê 20 iso_vectorstore files populated
‚òê ‚â•3 HOPs TAC-7 documentados
‚òê Tests passing (‚â•80% coverage)
‚òê Deployment guide (como colocar em produ√ß√£o)
‚òê Monitoring setup (dashboards configurados)
‚òê Handoff meeting scheduled (transfer√™ncia para time de ops)
```

**Deliverables Fase 5**:
- Documenta√ß√£o completa (PRIME + README + INSTRUCTIONS)
- Video walkthrough
- Handoff meeting completed

**Validation Gate**: Novo membro do time consegue fazer deployment seguindo documenta√ß√£o.

### M√©tricas de Sucesso do ADW

**Process Metrics**:
- Total duration: 2-4 semanas (discovery ‚Üí production)
- Rework rate: ‚â§15% (qu√£o frequentemente precisa refazer fases)
- Documentation completeness: 100% (nenhum placeholder/TODO restante)

**Quality Metrics**:
- 5-dimension score: ‚â•0.85
- Test coverage: ‚â•80%
- UAT success: ‚â•80%
- Production uptime (first month): ‚â•99.5%

### Anti-Patterns do ADW (Erros Fatais)

‚ùå **Pular Discovery**: "Sei o que preciso, vou direto pro c√≥digo"
‚Üí Resultado: Resolve problema errado ou de forma sub√≥tima

‚ùå **Design minimalista**: "Vou descobrindo enquanto codifico"
‚Üí Resultado: Refactoring constante, arquitetura spaghetti

‚ùå **Desenvolver sem testar**: "Vou testar tudo no fim"
‚Üí Resultado: Bugs descobertos tarde, dif√≠ceis de corrigir

‚ùå **Validation superficial**: "Testei 3 casos, funciona"
‚Üí Resultado: Edge cases quebram em produ√ß√£o

‚ùå **Documenta√ß√£o afterthought**: "Vou documentar quando tiver tempo"
‚Üí Resultado: Documenta√ß√£o never happens, agente √© unmaintainable

### Tools & Templates

**Template ADW Tracking**:
```markdown
# ADW Tracker: [Nome Agent]

## Status Dashboard
- DISCOVERY: ‚úÖ Complete (2024-11-15)
- DESIGN: ‚úÖ Complete (2024-11-18)
- DEVELOP: üü® In Progress (60% done)
- VALIDATE: ‚¨ú Not Started
- DOCUMENT: ‚¨ú Not Started

## Metrics
- Days elapsed: 8/20
- Budget spent: $450/$1000
- Quality score (current): 0.78/1.0
- Test coverage: 75%/80%
```

**Ferramentas recomendadas**:
- Project management: [OPEN_VARIABLE: ferramenta_gestao] (ex: Linear, GitHub Projects)
- Documentation: [OPEN_VARIABLE: ferramenta_docs] (ex: Notion, Obsidian)
- Testing: pytest + [OPEN_VARIABLE: ferramenta_eval]

---

**Tags**: adw, workflow, agent-development, 5-phase, discovery, design, develop, validate, document
**Palavras-chave**: ADW, workflow, 5 fases, desenvolvimento, agentes, processo, qualidade
**Origem**: curso_agent/PRIME.md + 06_MODULO_META_CONSTRUCAO.md + iso_vectorstore/11_ADW_workflow.md
**Processado**: 20251120
