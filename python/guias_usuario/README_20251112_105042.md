# CODEXA Test Suite

Automated testing for CODEXA HOP-001 Meta-Agent.

## ğŸ“‹ Overview

This test suite provides unit and integration tests for the CODEXA system, covering:
- HOP Orchestrator functionality
- CRUD operations
- Module registration and routing
- Safety guardrails

## ğŸš€ Quick Start

### Running All Tests

```bash
# From codexa/ directory
cd tests
pytest

# Or from project root
cd codexa
pytest tests/
```

### Running Specific Tests

```bash
# Run orchestrator tests only
pytest tests/test_orchestrator.py

# Run CRUD tests only
pytest tests/test_crud.py

# Run with verbose output
pytest -v

# Run with coverage
pytest --cov=../modules --cov=.. --cov-report=html
```

### Running by Markers

```bash
# Run only integration tests
pytest -m integration

# Skip slow tests
pytest -m "not slow"

# Run Windows-specific tests
pytest -m windows
```

## ğŸ“Š Test Coverage

Current test coverage:

| Module | Coverage | Tests | Status |
|--------|----------|-------|--------|
| `hop_orchestrator.py` | ~80% | 9 tests | âœ… |
| `modules/crud_ops.py` | ~60% | 12 tests | âœ… |
| `modules/scout_ops.py` | 0% | 0 tests | âš ï¸ TODO |
| `modules/ecommerce/*` | 0% | 0 tests | âš ï¸ TODO |
| `cli.py` | 0% | 0 tests | âš ï¸ TODO |

**Target:** 80% coverage overall

## ğŸ§ª Test Structure

```
tests/
â”œâ”€â”€ __init__.py           # Test package init
â”œâ”€â”€ conftest.py           # Shared fixtures
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ test_orchestrator.py  # HOP Orchestrator tests
â”œâ”€â”€ test_crud.py          # CRUD operations tests
â””â”€â”€ test_scout.py         # Scout operations tests (TODO)
```

## ğŸ“ Writing New Tests

### Basic Test Structure

```python
import pytest
from hop_orchestrator import HOPOrchestrator

@pytest.fixture
def orchestrator(tmp_path):
    return HOPOrchestrator(str(tmp_path))

def test_something(orchestrator):
    result = orchestrator.some_operation()
    assert result["success"] is True
```

### Using Shared Fixtures

Shared fixtures are defined in `conftest.py`:

```python
def test_with_sample_data(sample_markdown, sample_json):
    # Use sample_markdown and sample_json fixtures
    pass
```

### Markers

```python
@pytest.mark.integration
def test_full_workflow():
    # Integration test
    pass

@pytest.mark.slow
def test_large_repository():
    # Slow-running test
    pass

@pytest.mark.windows
def test_windows_encoding():
    # Windows-specific test
    pass
```

## ğŸ”§ Test Configuration

### pytest.ini (create if needed)

```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
markers =
    integration: Integration tests
    slow: Slow-running tests
    windows: Windows-specific tests
```

## ğŸ“¦ Dependencies

Tests require:
- `pytest>=7.4.0`
- `pytest-asyncio>=0.21.0` (for async tests)
- `pytest-cov>=4.1.0` (for coverage)

Install with:
```bash
pip install -r requirements.txt
```

## ğŸ› Troubleshooting

### Tests Not Found

Make sure you're running from the correct directory:
```bash
cd codexa/tests
pytest
```

Or use full path:
```bash
pytest codexa/tests/
```

### Import Errors

If you get import errors, ensure the parent directory is in `sys.path`:
```python
# At top of test file
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))
```

### Git-Related Failures

Some tests may fail if git operations are triggered. Use the `disable_git_operations` fixture from `conftest.py`.

## ğŸ“ˆ CI/CD Integration

### GitHub Actions Example

```yaml
name: CODEXA Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.10', '3.11', '3.12']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dependencies
      run: |
        pip install -r codexa/requirements.txt
    - name: Run tests
      run: |
        cd codexa
        pytest tests/ -v --cov
```

## ğŸ¯ Testing Checklist

Before creating a PR:

- [ ] All tests pass locally
- [ ] New features have corresponding tests
- [ ] Coverage doesn't decrease
- [ ] Tests pass on Windows (if applicable)
- [ ] No warnings from pytest
- [ ] Test names are descriptive

## ğŸ“š Further Reading

- [pytest documentation](https://docs.pytest.org/)
- [pytest fixtures](https://docs.pytest.org/en/stable/fixture.html)
- [pytest markers](https://docs.pytest.org/en/stable/mark.html)
- [pytest-cov](https://pytest-cov.readthedocs.io/)

---

**Last Updated:** 2025-11-11
**Status:** âœ… Active Development
