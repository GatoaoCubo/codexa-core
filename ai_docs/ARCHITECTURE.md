# ğŸ—ï¸ ECOMLM.CODEXA - System Architecture

## SYSTEM IDENTITY
You are examining the architecture of ECOMLM.CODEXA, a distributed multi-agent AI system designed for autonomous e-commerce operations.

## ARCHITECTURAL PRINCIPLES
1. **Agent Isolation**: Each agent operates independently with no shared state
2. **Event-Driven Communication**: Agents communicate through structured events
3. **JSON-First Configuration**: All workflows defined as versionable JSON
4. **Quality Gates**: Every output passes through validation layers
5. **Graceful Degradation**: System continues with partial agent failures

---

## ğŸ¯ HIGH-LEVEL ARCHITECTURE

```mermaid
graph TB
    User[User Interface] --> Orchestrator[CODEXA Orchestrator]

    Orchestrator --> Research[Pesquisa Agent]
    Orchestrator --> Generation[Anuncio Agent]
    Orchestrator --> Brand[Marca Agent]
    Orchestrator --> Knowledge[Conhecimento Agent]
    Orchestrator --> Strategy[Mentor Agent]
    Orchestrator --> Navigation[Scout Agent]

    Research --> Cache[(Research Cache)]
    Generation --> Templates[(Template Store)]
    Brand --> Assets[(Brand Assets)]
    Knowledge --> KB[(Knowledge Base)]
    Strategy --> Metrics[(KPI Store)]
    Navigation --> Index[(Code Index)]

    subgraph "External Services"
        Claude[Anthropic Claude API]
        GPT[OpenAI GPT API]
        Web[Web Services]
    end

    Research --> Claude
    Generation --> GPT
    Brand --> Claude
    Knowledge --> Claude
```

---

## ğŸ”§ COMPONENT ARCHITECTURE

### 1. ORCHESTRATION LAYER

#### CODEXA Orchestrator
```
RESPONSIBILITIES:
- Route commands to appropriate agents
- Manage agent lifecycle
- Handle inter-agent communication
- Maintain execution context
- Error recovery and retry logic

INTERFACES:
- REST API (FastAPI)
- CLI Commands (/slash commands)
- Event Bus (internal)

KEY FILES:
- app/server/server.py
- app/server/research_agent_orchestrator.py
- codexa/hop_orchestrator.py
```

### 2. AGENT LAYER

#### Agent Structure Pattern
```
Each Agent Follows:
â”œâ”€â”€ README.md               # Agent documentation
â”œâ”€â”€ {agent}.md             # Main command entry
â”œâ”€â”€ prompts/               # Prompt templates
â”‚   â”œâ”€â”€ main_agent.md      # Primary prompt
â”‚   â”œâ”€â”€ main_agent_hop.md  # HOP version
â”‚   â””â”€â”€ *.md              # Sub-prompts
â”œâ”€â”€ config/                # Configuration
â”‚   â”œâ”€â”€ agent_config.json
â”‚   â””â”€â”€ execution_plans/
â”œâ”€â”€ models.py              # Data models
â”œâ”€â”€ processor.py           # Core logic
â””â”€â”€ tests/                 # Test suite
```

### 3. DATA LAYER

#### Storage Architecture
```
Primary Storage:
- SQLite: Structured data, metadata
- JSON Files: Configuration, templates
- Markdown: Documentation, outputs
- Cache: Redis-like in-memory cache

Data Flow:
Input â†’ Validation â†’ Processing â†’ Storage â†’ Output
         â†“             â†“           â†“         â†“
      Rejected    Transformed  Indexed  Validated
```

---

## ğŸ¤– THE HOP FRAMEWORK

### Higher-Order Prompt Architecture

```
CONCEPT:
Prompts are not strings but composable data structures

STRUCTURE:
1. Orchestrator Level
   - Receives user intent
   - Selects execution plan

2. Execution Plan (JSON)
   - Defines workflow steps
   - Sets quality thresholds
   - Configures validation rules

3. Prompt Modules
   - Atomic, reusable components
   - Input/output contracts
   - Version controlled

4. Validation Layer
   - Schema validation
   - Quality scoring
   - Compliance checks
```

### HOP Execution Flow
```python
# Pseudo-code representation
def execute_hop_workflow(user_input):
    # 1. Parse intent
    intent = parse_user_intent(user_input)

    # 2. Load execution plan
    plan = load_execution_plan(f"{intent.agent}/{intent.action}.json")

    # 3. Execute steps
    context = {}
    for step in plan.steps:
        prompt = load_prompt_module(step.prompt)
        result = execute_prompt(prompt, context)

        # 4. Validate
        if not validate_result(result, step.validation):
            if step.on_failure == "abort":
                raise ValidationError
            else:  # warn
                log_warning(result)

        # 5. Update context
        context[step.name] = result

    return format_output(context, plan.output_format)
```

---

## ğŸ“¡ INTEGRATION ARCHITECTURE

### API Gateway Pattern
```
Client Request
     â†“
[API Gateway]
     â†“
Rate Limiting â†’ Authentication â†’ Routing
                                    â†“
                            [Agent Selection]
                                    â†“
                            Agent Execution
                                    â†“
                            Response Formatting
                                    â†“
                              Client Response
```

### External Service Integration
```
1. LLM Services (Anthropic, OpenAI)
   - Connection pooling
   - Automatic retry with exponential backoff
   - Token counting and optimization
   - Response caching

2. Web Services
   - Visual scraping (screenshot-based)
   - Anti-bot detection avoidance
   - Concurrent request management
   - Result deduplication

3. File System
   - Atomic writes
   - Lock-free reads
   - Automatic backup
   - Version control integration
```

---

## ğŸ” SECURITY ARCHITECTURE

### Security Layers
```
1. Input Validation
   - SQL injection prevention
   - XSS protection
   - Command injection blocking
   - Path traversal prevention

2. Authentication & Authorization
   - API key management
   - Role-based access control
   - Rate limiting per user/IP
   - Session management

3. Data Protection
   - Encryption at rest (sensitive data)
   - Secure API key storage
   - PII anonymization
   - Audit logging

4. Compliance
   - LGPD compliance (Brazilian data protection)
   - ANVISA/INMETRO validation
   - Marketplace terms adherence
   - Content moderation
```

---

## ğŸš€ DEPLOYMENT ARCHITECTURE

### Development Environment
```
Local Development:
â”œâ”€â”€ Backend: uv run python server.py (port 8000)
â”œâ”€â”€ Frontend: npm run dev (port 5173)
â”œâ”€â”€ Database: SQLite (local file)
â””â”€â”€ Cache: In-memory

Requirements:
- Python 3.12+
- Node.js 18+
- 8GB RAM minimum
- 10GB disk space
```

### Production Architecture
```
Recommended Stack:
â”œâ”€â”€ Load Balancer: Nginx/Caddy
â”œâ”€â”€ Application: Gunicorn + FastAPI
â”œâ”€â”€ Database: PostgreSQL/MySQL
â”œâ”€â”€ Cache: Redis
â”œâ”€â”€ Queue: Celery + RabbitMQ
â”œâ”€â”€ Storage: S3-compatible
â””â”€â”€ Monitoring: Prometheus + Grafana

Scaling Strategy:
- Horizontal scaling for agents
- Read replicas for database
- CDN for static assets
- Queue-based task distribution
```

---

## ğŸ“Š PERFORMANCE ARCHITECTURE

### Optimization Strategies
```
1. Caching Layers
   - LLM response cache (15 min TTL)
   - Research result cache (1 hour TTL)
   - Template cache (24 hour TTL)
   - Static asset cache (7 days)

2. Parallel Processing
   - Concurrent agent execution
   - Batch processing for multiple items
   - Async I/O for external calls
   - Worker pool for CPU-intensive tasks

3. Resource Management
   - Connection pooling
   - Memory-mapped files for large data
   - Lazy loading of resources
   - Automatic cleanup routines
```

### Performance Targets
```
Response Times:
- API latency: < 100ms (p50)
- Research completion: < 30 minutes
- Ad generation: < 3 minutes
- Knowledge extraction: < 5 minutes

Throughput:
- 100+ concurrent users
- 1000+ requests/minute
- 10,000+ products/day
- 1M+ knowledge cards
```

---

## ğŸ”„ DATA FLOW ARCHITECTURE

### Research â†’ Generation Flow
```
1. User Input
   â†“
2. Research Agent
   â”œâ”€â”€ Market analysis
   â”œâ”€â”€ Competitor scan
   â””â”€â”€ SEO extraction
   â†“
3. Research Notes (Markdown)
   â†“
4. Anuncio Agent
   â”œâ”€â”€ Title generation
   â”œâ”€â”€ Description building
   â””â”€â”€ Keyword optimization
   â†“
5. Validation Layer
   â”œâ”€â”€ Compliance check
   â”œâ”€â”€ SEO validation
   â””â”€â”€ Brand consistency
   â†“
6. Final Output (JSON + Markdown)
```

### Knowledge Processing Pipeline
```
1. Raw Input (any format)
   â†“
2. Extraction
   â”œâ”€â”€ Text extraction
   â”œâ”€â”€ Metadata parsing
   â””â”€â”€ Entity recognition
   â†“
3. Classification
   â”œâ”€â”€ Category assignment
   â”œâ”€â”€ Quality scoring
   â””â”€â”€ Relevance ranking
   â†“
4. Synthesis
   â”œâ”€â”€ Deduplication
   â”œâ”€â”€ Consolidation
   â””â”€â”€ Enrichment
   â†“
5. Validation
   â”œâ”€â”€ Completeness check
   â”œâ”€â”€ Accuracy verification
   â””â”€â”€ Consistency validation
   â†“
6. Knowledge Card (JSON)
```

---

## ğŸ› ï¸ DEVELOPMENT PATTERNS

### Design Patterns Used
```
1. Strategy Pattern
   - Different strategies per marketplace
   - Swappable LLM providers
   - Multiple validation strategies

2. Chain of Responsibility
   - Multi-stage validation pipeline
   - Error handling cascade
   - Request preprocessing chain

3. Factory Pattern
   - Agent creation
   - Prompt template generation
   - Response formatter creation

4. Observer Pattern
   - Event-driven agent communication
   - Progress tracking
   - Error notification

5. Facade Pattern
   - Simplified API interface
   - Complex agent orchestration
   - External service abstraction
```

### Code Organization Principles
```
1. Single Responsibility
   - One agent, one purpose
   - Atomic prompt modules
   - Focused utility functions

2. Open/Closed
   - Extensible through configuration
   - New agents without core changes
   - Plugin-based architecture

3. Dependency Inversion
   - Interfaces over implementations
   - Configurable dependencies
   - Mock-friendly testing

4. Don't Repeat Yourself
   - Shared utility modules
   - Reusable prompt components
   - Common validation rules
```

---

## ğŸ” MONITORING & OBSERVABILITY

### Metrics Collection
```
Application Metrics:
- Request rate and latency
- Agent execution time
- Cache hit/miss ratio
- Error rate by type

Business Metrics:
- Listings generated/day
- Average quality score
- Conversion rate improvement
- Time saved per task

System Metrics:
- CPU/Memory usage
- Disk I/O
- Network throughput
- Database performance
```

### Logging Architecture
```
Log Levels:
- DEBUG: Detailed execution flow
- INFO: Normal operations
- WARNING: Degraded performance
- ERROR: Recoverable failures
- CRITICAL: System failures

Log Structure:
{
  "timestamp": "ISO-8601",
  "level": "INFO",
  "agent": "pesquisa",
  "action": "research_complete",
  "duration_ms": 1823000,
  "metadata": {...}
}
```

---

## ğŸ”® FUTURE ARCHITECTURE

### Planned Enhancements
```
1. Microservices Migration
   - One service per agent
   - Kubernetes orchestration
   - Service mesh (Istio)

2. Event Streaming
   - Kafka/Pulsar integration
   - Real-time processing
   - Event sourcing

3. ML Pipeline
   - Automated training
   - Model versioning
   - A/B testing framework

4. Multi-Region Support
   - Geographic distribution
   - Data sovereignty
   - Latency optimization
```

---

> **Architecture Note**: This document represents the current system architecture. As the system evolves, this documentation is updated to reflect architectural changes and improvements.